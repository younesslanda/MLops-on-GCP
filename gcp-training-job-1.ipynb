{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72745e89-f6a1-4558-bdab-d0fd24b00091",
   "metadata": {},
   "source": [
    "Importing packages\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e071b2e1-035e-4e44-89c3-55e3c9e96614",
   "metadata": {},
   "source": [
    "__We need to run the scripts install requirements.sh__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bc8e072-2f5a-4a1d-b7fb-d14136c58b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import uuid\n",
    "import time\n",
    "import tempfile\n",
    "\n",
    "from googleapiclient import discovery\n",
    "from googleapiclient import errors\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from jinja2 import Template\n",
    "from kfp.components import func_to_container_op\n",
    "from typing import NamedTuple\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3cf731a-8795-4ffa-9cee-5a82d597cea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zeta-rush-341516\n"
     ]
    }
   ],
   "source": [
    "!(gcloud config get-value core/project)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28073f75-9a2a-4026-9367-c459a1f8ecab",
   "metadata": {},
   "source": [
    "Preparing the dataset\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56119eaf-79f6-40e9-8803-82ed50d72fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = !(gcloud config get-value core/project)\n",
    "PROJECT_ID = PROJECT_ID[0]\n",
    "DATASET_ID='covertype_dataset'\n",
    "DATASET_LOCATION='US'\n",
    "TABLE_ID='covertype'\n",
    "DATA_SOURCE='gs://workshop-datasets/covertype/small/dataset.csv'\n",
    "\n",
    "SCHEMA='Elevation:INTEGER,Aspect:INTEGER,Slope:INTEGER,Horizontal_Distance_To_Hydrology:\\\n",
    "INTEGER,Vertical_Distance_To_Hydrology:INTEGER,Horizontal_Distance_To_Roadways:INTEGER,Hillshade_9am:\\\n",
    "INTEGER,Hillshade_Noon:INTEGER,Hillshade_3pm:INTEGER,Horizontal_Distance_To_Fire_Points:INTEGER,\\\n",
    "Wilderness_Area:STRING,Soil_Type:STRING,Cover_Type:INTEGER'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdd5927-d9ad-4226-933f-1c5bb8e3dd04",
   "metadata": {},
   "source": [
    "__We create the BigQuery dataset and upload the Covertype csv data into a table__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12708641-f74e-41c5-94df-31d8c3d8d7ec",
   "metadata": {},
   "source": [
    "__The pipeline ingests data from BigQuery. The cell below uploads the Covertype dataset to BigQuery__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b62a89df-8e67-4b94-b2e5-72238b26e3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BigQuery error in mk operation: Dataset 'zeta-rush-341516:covertype_dataset'\n",
      "already exists.\n"
     ]
    }
   ],
   "source": [
    "!bq --location=$DATASET_LOCATION --project_id=$PROJECT_ID mk --dataset $DATASET_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0e75540-fd5b-4274-93fc-da8182c7c926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting on bqjob_r1a261ada7bedac6e_0000017f95549ef8_1 ... (2s) Current status: DONE   \n"
     ]
    }
   ],
   "source": [
    "!bq --project_id=$PROJECT_ID --dataset_id=$DATASET_ID load \\\n",
    "--source_format=CSV \\\n",
    "--skip_leading_rows=1 \\\n",
    "--replace \\\n",
    "$TABLE_ID \\\n",
    "$DATA_SOURCE \\\n",
    "$SCHEMA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fa42c0-a1c0-4bdb-9f5b-1c0b30fe2a3d",
   "metadata": {},
   "source": [
    "Configuring environment settings\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afb4e58f-f600-4d13-8dd1-2c41fa04d753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://artifacts.zeta-rush-341516.appspot.com/\n",
      "gs://cloud-ai-platform-4aa74d0a-5386-461c-8135-3f0feac88a35/\n",
      "gs://cloud-ai-platform-fffcccf5-f8f6-480b-9bb1-7a0a20be6be1/\n",
      "gs://mlops-youness/\n",
      "gs://storage_bucket_speech/\n",
      "gs://zeta-rush-341516_cloudbuild/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7828cbf5-af80-4481-95a2-b6cfead7c1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "ARTIFACT_STORE = 'gs://mlops-youness'\n",
    "\n",
    "PROJECT_ID = !(gcloud config get-value core/project)\n",
    "PROJECT_ID = PROJECT_ID[0]\n",
    "DATA_ROOT='{}/data'.format(ARTIFACT_STORE)\n",
    "JOB_DIR_ROOT='{}/jobs'.format(ARTIFACT_STORE)\n",
    "TRAINING_FILE_PATH='{}/{}/{}'.format(DATA_ROOT, 'training', 'dataset.csv')\n",
    "VALIDATION_FILE_PATH='{}/{}/{}'.format(DATA_ROOT, 'validation', 'dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215fee0d-e24f-49c2-824a-4e1a198705c5",
   "metadata": {},
   "source": [
    "Exploring the Covertype dataset\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbdefe92-cb30-471d-bbd5-c546f16a1ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 0.00s: 100%|██████████| 2/2 [00:00<00:00, 1215.56query/s]                        \n",
      "Downloading: 100%|██████████| 100000/100000 [00:01<00:00, 92715.65rows/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <th>Wilderness_Area</th>\n",
       "      <th>Soil_Type</th>\n",
       "      <th>Cover_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2085</td>\n",
       "      <td>256</td>\n",
       "      <td>18</td>\n",
       "      <td>150</td>\n",
       "      <td>27</td>\n",
       "      <td>738</td>\n",
       "      <td>176</td>\n",
       "      <td>248</td>\n",
       "      <td>208</td>\n",
       "      <td>914</td>\n",
       "      <td>Cache</td>\n",
       "      <td>C2702</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2125</td>\n",
       "      <td>256</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>871</td>\n",
       "      <td>169</td>\n",
       "      <td>248</td>\n",
       "      <td>215</td>\n",
       "      <td>300</td>\n",
       "      <td>Cache</td>\n",
       "      <td>C2702</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2146</td>\n",
       "      <td>256</td>\n",
       "      <td>34</td>\n",
       "      <td>150</td>\n",
       "      <td>62</td>\n",
       "      <td>1253</td>\n",
       "      <td>122</td>\n",
       "      <td>237</td>\n",
       "      <td>239</td>\n",
       "      <td>511</td>\n",
       "      <td>Cache</td>\n",
       "      <td>C2702</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2186</td>\n",
       "      <td>256</td>\n",
       "      <td>38</td>\n",
       "      <td>210</td>\n",
       "      <td>102</td>\n",
       "      <td>1294</td>\n",
       "      <td>109</td>\n",
       "      <td>232</td>\n",
       "      <td>244</td>\n",
       "      <td>552</td>\n",
       "      <td>Cache</td>\n",
       "      <td>C2702</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2831</td>\n",
       "      <td>256</td>\n",
       "      <td>25</td>\n",
       "      <td>277</td>\n",
       "      <td>183</td>\n",
       "      <td>1706</td>\n",
       "      <td>153</td>\n",
       "      <td>246</td>\n",
       "      <td>225</td>\n",
       "      <td>1485</td>\n",
       "      <td>Commanche</td>\n",
       "      <td>C2705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>3136</td>\n",
       "      <td>254</td>\n",
       "      <td>12</td>\n",
       "      <td>319</td>\n",
       "      <td>60</td>\n",
       "      <td>5734</td>\n",
       "      <td>193</td>\n",
       "      <td>248</td>\n",
       "      <td>193</td>\n",
       "      <td>2467</td>\n",
       "      <td>Rawah</td>\n",
       "      <td>C7746</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>3242</td>\n",
       "      <td>254</td>\n",
       "      <td>12</td>\n",
       "      <td>636</td>\n",
       "      <td>148</td>\n",
       "      <td>3551</td>\n",
       "      <td>193</td>\n",
       "      <td>248</td>\n",
       "      <td>193</td>\n",
       "      <td>2010</td>\n",
       "      <td>Commanche</td>\n",
       "      <td>C7757</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>2071</td>\n",
       "      <td>255</td>\n",
       "      <td>12</td>\n",
       "      <td>234</td>\n",
       "      <td>63</td>\n",
       "      <td>342</td>\n",
       "      <td>192</td>\n",
       "      <td>247</td>\n",
       "      <td>193</td>\n",
       "      <td>247</td>\n",
       "      <td>Cache</td>\n",
       "      <td>C2706</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>3248</td>\n",
       "      <td>255</td>\n",
       "      <td>12</td>\n",
       "      <td>730</td>\n",
       "      <td>113</td>\n",
       "      <td>725</td>\n",
       "      <td>192</td>\n",
       "      <td>247</td>\n",
       "      <td>193</td>\n",
       "      <td>2724</td>\n",
       "      <td>Commanche</td>\n",
       "      <td>C7756</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>3153</td>\n",
       "      <td>255</td>\n",
       "      <td>12</td>\n",
       "      <td>404</td>\n",
       "      <td>116</td>\n",
       "      <td>2139</td>\n",
       "      <td>192</td>\n",
       "      <td>247</td>\n",
       "      <td>193</td>\n",
       "      <td>994</td>\n",
       "      <td>Commanche</td>\n",
       "      <td>C7756</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "0           2085     256     18                               150   \n",
       "1           2125     256     20                                30   \n",
       "2           2146     256     34                               150   \n",
       "3           2186     256     38                               210   \n",
       "4           2831     256     25                               277   \n",
       "...          ...     ...    ...                               ...   \n",
       "99995       3136     254     12                               319   \n",
       "99996       3242     254     12                               636   \n",
       "99997       2071     255     12                               234   \n",
       "99998       3248     255     12                               730   \n",
       "99999       3153     255     12                               404   \n",
       "\n",
       "       Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "0                                  27                              738   \n",
       "1                                  12                              871   \n",
       "2                                  62                             1253   \n",
       "3                                 102                             1294   \n",
       "4                                 183                             1706   \n",
       "...                               ...                              ...   \n",
       "99995                              60                             5734   \n",
       "99996                             148                             3551   \n",
       "99997                              63                              342   \n",
       "99998                             113                              725   \n",
       "99999                             116                             2139   \n",
       "\n",
       "       Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
       "0                176             248            208   \n",
       "1                169             248            215   \n",
       "2                122             237            239   \n",
       "3                109             232            244   \n",
       "4                153             246            225   \n",
       "...              ...             ...            ...   \n",
       "99995            193             248            193   \n",
       "99996            193             248            193   \n",
       "99997            192             247            193   \n",
       "99998            192             247            193   \n",
       "99999            192             247            193   \n",
       "\n",
       "       Horizontal_Distance_To_Fire_Points Wilderness_Area Soil_Type  \\\n",
       "0                                     914           Cache     C2702   \n",
       "1                                     300           Cache     C2702   \n",
       "2                                     511           Cache     C2702   \n",
       "3                                     552           Cache     C2702   \n",
       "4                                    1485       Commanche     C2705   \n",
       "...                                   ...             ...       ...   \n",
       "99995                                2467           Rawah     C7746   \n",
       "99996                                2010       Commanche     C7757   \n",
       "99997                                 247           Cache     C2706   \n",
       "99998                                2724       Commanche     C7756   \n",
       "99999                                 994       Commanche     C7756   \n",
       "\n",
       "       Cover_Type  \n",
       "0               5  \n",
       "1               2  \n",
       "2               2  \n",
       "3               2  \n",
       "4               1  \n",
       "...           ...  \n",
       "99995           1  \n",
       "99996           0  \n",
       "99997           2  \n",
       "99998           1  \n",
       "99999           1  \n",
       "\n",
       "[100000 rows x 13 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT *\n",
    "FROM `covertype_dataset.covertype`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff3f963-91f3-4be7-9177-51d8fec51129",
   "metadata": {},
   "source": [
    "Creating a training split\n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0056ea9c-3eb7-47ed-83c2-81e7174e40d2",
   "metadata": {},
   "source": [
    "__We Run the query below in order to have repeatable sampling of the data in BigQuery__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "633ce65c-b03e-41ee-be10-ec5b88fdd356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting on bqjob_r62de6020f6501c97_0000017f9555177a_1 ... (1s) Current status: DONE   \n"
     ]
    }
   ],
   "source": [
    "!bq query \\\n",
    "-n 0 \\\n",
    "--destination_table covertype_dataset.training \\\n",
    "--replace \\\n",
    "--use_legacy_sql=false \\\n",
    "'SELECT * \\\n",
    "FROM `covertype_dataset.covertype` AS cover \\\n",
    "WHERE \\\n",
    "MOD(ABS(FARM_FINGERPRINT(TO_JSON_STRING(cover))), 10) IN (1, 2, 3, 4)' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cada459-3368-4c2e-8f2d-fd653ff60ca0",
   "metadata": {},
   "source": [
    "__We export the BigQuery training table to GCS at $TRAINING_FILE_PATH__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e13b1b53-7b24-4988-9fa8-bfe871785cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting on bqjob_r1a578ffe791da479_0000017f95552b1d_1 ... (0s) Current status: DONE   \n"
     ]
    }
   ],
   "source": [
    "!bq extract \\\n",
    "--destination_format CSV \\\n",
    "covertype_dataset.training \\\n",
    "$TRAINING_FILE_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf54fdab-e3d5-484b-8f54-1f4cba6e9bd9",
   "metadata": {},
   "source": [
    "Creating a validation split\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc7f5cf-8443-4c34-aa6e-1f05993515e3",
   "metadata": {},
   "source": [
    " __We create a validation split that takes 10% of the data using the `bq` command and export this split into the BigQuery table `covertype_dataset.validation`__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9332737-32fc-492c-a636-ae8c8c22dacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting on bqjob_r3bc65f64f09d8a59_0000017f95555861_1 ... (1s) Current status: DONE   \n"
     ]
    }
   ],
   "source": [
    "!bq query \\\n",
    "-n 0 \\\n",
    "--destination_table covertype_dataset.validation \\\n",
    "--replace \\\n",
    "--use_legacy_sql=false \\\n",
    "'SELECT * \\\n",
    "FROM `covertype_dataset.covertype` AS cover \\\n",
    "WHERE \\\n",
    "MOD(ABS(FARM_FINGERPRINT(TO_JSON_STRING(cover))), 10) IN (8)' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4d9362b-ca4a-4d40-9582-c886500fa2ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting on bqjob_r23b86d45a22ec838_0000017f955596a9_1 ... (0s) Current status: DONE   \n"
     ]
    }
   ],
   "source": [
    "!bq extract \\\n",
    "--destination_format CSV \\\n",
    "covertype_dataset.validation \\\n",
    "$VALIDATION_FILE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c05b767-34d3-4222-9912-795eaf7e5eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('gs://mlops-youness/data/training/dataset.csv',\n",
       " 'gs://mlops-youness/data/validation/dataset.csv')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAINING_FILE_PATH, VALIDATION_FILE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01547b72-ea5d-46c6-b9b6-62e680059c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40009, 13)\n",
      "(9836, 13)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(TRAINING_FILE_PATH)\n",
    "df_validation = pd.read_csv(VALIDATION_FILE_PATH)\n",
    "print(df_train.shape)\n",
    "print(df_validation.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2decc451-8bb9-4de4-bbe4-3e015ece2fa5",
   "metadata": {},
   "source": [
    "The training application\n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de77f39-bed7-443f-8604-40db0adbb92c",
   "metadata": {},
   "source": [
    "The training pipeline preprocesses data by standardizing all numeric features using `sklearn.preprocessing.StandardScaler` and encoding all categorical features using `sklearn.preprocessing.OneHotEncoder`. It uses stochastic gradient descent linear classifier (SGDClassifier) for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "910f62bf-dbf7-4113-b2bb-71ad2acb230d",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_feature_indexes = slice(0, 10)\n",
    "categorical_feature_indexes = slice(10, 12)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_feature_indexes),\n",
    "        ('cat', OneHotEncoder(), categorical_feature_indexes) \n",
    "    ])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', SGDClassifier(loss='log', tol=1e-3))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39b615a2-3421-4d65-9255-bccceefadea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features_type_map = {feature: 'float64' for feature in df_train.columns[numeric_feature_indexes]}\n",
    "\n",
    "df_train = df_train.astype(num_features_type_map)\n",
    "df_validation = df_validation.astype(num_features_type_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb32a5f2-4725-4ce6-b657-9d560a870253",
   "metadata": {},
   "source": [
    "__Run the pipeline locally.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0db1f316-94de-4420-853a-55bcfe7c9fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num', StandardScaler(),\n",
       "                                                  slice(0, 10, None)),\n",
       "                                                 ('cat', OneHotEncoder(),\n",
       "                                                  slice(10, 12, None))])),\n",
       "                ('classifier',\n",
       "                 SGDClassifier(alpha=0.001, loss='log', max_iter=200))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = df_train.drop('Cover_Type', axis=1)\n",
    "y_train = df_train['Cover_Type']\n",
    "X_validation = df_validation.drop('Cover_Type', axis=1)\n",
    "y_validation = df_validation['Cover_Type']\n",
    "\n",
    "pipeline.set_params(classifier__alpha=0.001, classifier__max_iter=200)\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5001cbd8-cee2-4fb2-99e6-17214fbc5387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6982513216754779\n"
     ]
    }
   ],
   "source": [
    "accuracy = pipeline.score(X_validation, y_validation)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1058d6d-2c76-43ca-893d-88f7b8c000de",
   "metadata": {},
   "source": [
    "__Prepare the hyperparameter tuning application.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e71b2925-6b20-4767-894b-8cc4e59dd2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_APP_FOLDER = 'training_app'\n",
    "os.makedirs(TRAINING_APP_FOLDER, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0f01dfc-3454-44e3-8547-a35e22c0cf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_NAME='trainer_image'\n",
    "IMAGE_TAG='latest'\n",
    "IMAGE_URI='gcr.io/{}/{}:{}'.format(PROJECT_ID, IMAGE_NAME, IMAGE_TAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "76a4d8dc-6084-43b0-bc40-e91c3ab66c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gcr.io/zeta-rush-341516/trainer_image:latest'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMAGE_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014e973b-8a88-4e10-b434-dd166347308b",
   "metadata": {},
   "source": [
    "__Build the docker image__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "30bb30c1-2cba-4bef-9157-11a72300382c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporary tarball archive of 6 file(s) totalling 6.0 KiB before compression.\n",
      "Uploading tarball of [training_app] to [gs://zeta-rush-341516_cloudbuild/source/1647477979.084049-6af7f304c194456c88a30a32f6ef1f0f.tgz]\n",
      "Created [https://cloudbuild.googleapis.com/v1/projects/zeta-rush-341516/locations/global/builds/3d083302-0757-42da-a50a-341705ff8e6b].\n",
      "Logs are available at [https://console.cloud.google.com/cloud-build/builds/3d083302-0757-42da-a50a-341705ff8e6b?project=156920671469].\n",
      "----------------------------- REMOTE BUILD OUTPUT ------------------------------\n",
      "starting build \"3d083302-0757-42da-a50a-341705ff8e6b\"\n",
      "\n",
      "FETCHSOURCE\n",
      "Fetching storage object: gs://zeta-rush-341516_cloudbuild/source/1647477979.084049-6af7f304c194456c88a30a32f6ef1f0f.tgz#1647477979401432\n",
      "Copying gs://zeta-rush-341516_cloudbuild/source/1647477979.084049-6af7f304c194456c88a30a32f6ef1f0f.tgz#1647477979401432...\n",
      "/ [1 files][  1.7 KiB/  1.7 KiB]                                                \n",
      "Operation completed over 1 objects/1.7 KiB.\n",
      "BUILD\n",
      "Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "Sending build context to Docker daemon  11.78kB\n",
      "Step 1/5 : FROM gcr.io/deeplearning-platform-release/base-cpu\n",
      "latest: Pulling from deeplearning-platform-release/base-cpu\n",
      "08c01a0ec47e: Already exists\n",
      "bd48248908bf: Pulling fs layer\n",
      "bff5af70d0ac: Pulling fs layer\n",
      "7a863f90d65e: Pulling fs layer\n",
      "4f4fb700ef54: Pulling fs layer\n",
      "a75f2205d0be: Pulling fs layer\n",
      "8f06f1106c17: Pulling fs layer\n",
      "5a8ebf5e5925: Pulling fs layer\n",
      "4441047ea5de: Pulling fs layer\n",
      "1253e9ba8ab7: Pulling fs layer\n",
      "8b11a2e9d128: Pulling fs layer\n",
      "61bd4f2d2e6f: Pulling fs layer\n",
      "f8d36dcce25d: Pulling fs layer\n",
      "f1b941ed5a20: Pulling fs layer\n",
      "9746114c8daf: Pulling fs layer\n",
      "a8c487052d75: Pulling fs layer\n",
      "030a072533c0: Pulling fs layer\n",
      "59518298f277: Pulling fs layer\n",
      "4f4fb700ef54: Waiting\n",
      "a75f2205d0be: Waiting\n",
      "8f06f1106c17: Waiting\n",
      "8b11a2e9d128: Waiting\n",
      "61bd4f2d2e6f: Waiting\n",
      "f8d36dcce25d: Waiting\n",
      "5a8ebf5e5925: Waiting\n",
      "f1b941ed5a20: Waiting\n",
      "4441047ea5de: Waiting\n",
      "1253e9ba8ab7: Waiting\n",
      "9746114c8daf: Waiting\n",
      "a8c487052d75: Waiting\n",
      "030a072533c0: Waiting\n",
      "59518298f277: Waiting\n",
      "bd48248908bf: Verifying Checksum\n",
      "bd48248908bf: Download complete\n",
      "4f4fb700ef54: Verifying Checksum\n",
      "4f4fb700ef54: Download complete\n",
      "bd48248908bf: Pull complete\n",
      "a75f2205d0be: Verifying Checksum\n",
      "a75f2205d0be: Download complete\n",
      "7a863f90d65e: Verifying Checksum\n",
      "7a863f90d65e: Download complete\n",
      "8f06f1106c17: Verifying Checksum\n",
      "8f06f1106c17: Download complete\n",
      "5a8ebf5e5925: Download complete\n",
      "4441047ea5de: Verifying Checksum\n",
      "4441047ea5de: Download complete\n",
      "1253e9ba8ab7: Verifying Checksum\n",
      "1253e9ba8ab7: Download complete\n",
      "8b11a2e9d128: Verifying Checksum\n",
      "8b11a2e9d128: Download complete\n",
      "61bd4f2d2e6f: Verifying Checksum\n",
      "61bd4f2d2e6f: Download complete\n",
      "f8d36dcce25d: Verifying Checksum\n",
      "f8d36dcce25d: Download complete\n",
      "f1b941ed5a20: Verifying Checksum\n",
      "f1b941ed5a20: Download complete\n",
      "9746114c8daf: Verifying Checksum\n",
      "9746114c8daf: Download complete\n",
      "a8c487052d75: Verifying Checksum\n",
      "a8c487052d75: Download complete\n",
      "59518298f277: Verifying Checksum\n",
      "59518298f277: Download complete\n",
      "bff5af70d0ac: Verifying Checksum\n",
      "bff5af70d0ac: Download complete\n",
      "030a072533c0: Download complete\n",
      "bff5af70d0ac: Pull complete\n",
      "7a863f90d65e: Pull complete\n",
      "4f4fb700ef54: Pull complete\n",
      "a75f2205d0be: Pull complete\n",
      "8f06f1106c17: Pull complete\n",
      "5a8ebf5e5925: Pull complete\n",
      "4441047ea5de: Pull complete\n",
      "1253e9ba8ab7: Pull complete\n",
      "8b11a2e9d128: Pull complete\n",
      "61bd4f2d2e6f: Pull complete\n",
      "f8d36dcce25d: Pull complete\n",
      "f1b941ed5a20: Pull complete\n",
      "9746114c8daf: Pull complete\n",
      "a8c487052d75: Pull complete\n",
      "030a072533c0: Pull complete\n",
      "59518298f277: Pull complete\n",
      "Digest: sha256:4dec453a1946d621666e2abf5d1bc46353ec056c9682694a169c2785a57d7bc7\n",
      "Status: Downloaded newer image for gcr.io/deeplearning-platform-release/base-cpu:latest\n",
      " ---> bc8479139130\n",
      "Step 2/5 : RUN pip install -U fire cloudml-hypertune scikit-learn==0.20.4 pandas==0.24.2\n",
      " ---> Running in 357533527bc2\n",
      "Collecting fire\n",
      "  Downloading fire-0.4.0.tar.gz (87 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 87.7/87.7 KB 4.2 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting cloudml-hypertune\n",
      "  Downloading cloudml-hypertune-0.1.0.dev6.tar.gz (3.2 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting scikit-learn==0.20.4\n",
      "  Downloading scikit_learn-0.20.4-cp37-cp37m-manylinux1_x86_64.whl (5.4 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.4/5.4 MB 43.1 MB/s eta 0:00:00\n",
      "Collecting pandas==0.24.2\n",
      "  Downloading pandas-0.24.2-cp37-cp37m-manylinux1_x86_64.whl (10.1 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.1/10.1 MB 50.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy>=0.13.3 in /opt/conda/lib/python3.7/site-packages (from scikit-learn==0.20.4) (1.7.3)\n",
      "Requirement already satisfied: numpy>=1.8.2 in /opt/conda/lib/python3.7/site-packages (from scikit-learn==0.20.4) (1.19.5)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /opt/conda/lib/python3.7/site-packages (from pandas==0.24.2) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2011k in /opt/conda/lib/python3.7/site-packages (from pandas==0.24.2) (2021.3)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from fire) (1.16.0)\n",
      "Collecting termcolor\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: fire, cloudml-hypertune, termcolor\n",
      "  Building wheel for fire (setup.py): started\n",
      "  Building wheel for fire (setup.py): finished with status 'done'\n",
      "  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115942 sha256=c0135569d43a1caa842d863cb4972f41f71bf98e191fa0ee57238e9f2a00351f\n",
      "  Stored in directory: /root/.cache/pip/wheels/8a/67/fb/2e8a12fa16661b9d5af1f654bd199366799740a85c64981226\n",
      "  Building wheel for cloudml-hypertune (setup.py): started\n",
      "  Building wheel for cloudml-hypertune (setup.py): finished with status 'done'\n",
      "  Created wheel for cloudml-hypertune: filename=cloudml_hypertune-0.1.0.dev6-py2.py3-none-any.whl size=3987 sha256=1e0377bdf75c697d6ffdbeb43139a6a8d89f8bc1b2ba561adf8e09ab53da06dd\n",
      "  Stored in directory: /root/.cache/pip/wheels/a7/ff/87/e7bed0c2741fe219b3d6da67c2431d7f7fedb183032e00f81e\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4848 sha256=956c5d897a083e59039c138655a0a935954fe01f2c503265a5ec3666978a329b\n",
      "  Stored in directory: /root/.cache/pip/wheels/3f/e3/ec/8a8336ff196023622fbcb36de0c5a5c218cbb24111d1d4c7f2\n",
      "Successfully built fire cloudml-hypertune termcolor\n",
      "Installing collected packages: termcolor, cloudml-hypertune, fire, scikit-learn, pandas\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.0.2\n",
      "    Uninstalling scikit-learn-1.0.2:\n",
      "      Successfully uninstalled scikit-learn-1.0.2\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.3.5\n",
      "    Uninstalling pandas-1.3.5:\n",
      "      Successfully uninstalled pandas-1.3.5\n",
      "\u001b[91mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "visions 0.7.1 requires pandas>=0.25.3, but you have pandas 0.24.2 which is incompatible.\n",
      "statsmodels 0.13.2 requires pandas>=0.25, but you have pandas 0.24.2 which is incompatible.\n",
      "phik 0.12.0 requires pandas>=0.25.1, but you have pandas 0.24.2 which is incompatible.\n",
      "pandas-profiling 3.0.0 requires pandas!=1.0.0,!=1.0.1,!=1.0.2,!=1.1.0,>=0.25.3, but you have pandas 0.24.2 which is incompatible.\n",
      "pandas-profiling 3.0.0 requires tangled-up-in-unicode==0.1.0, but you have tangled-up-in-unicode 0.2.0 which is incompatible.\n",
      "\u001b[0mSuccessfully installed cloudml-hypertune-0.1.0.dev6 fire-0.4.0 pandas-0.24.2 scikit-learn-0.20.4 termcolor-1.1.0\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0mRemoving intermediate container 357533527bc2\n",
      " ---> 16d437e2b4ef\n",
      "Step 3/5 : WORKDIR /app\n",
      " ---> Running in 61c97c3ab68d\n",
      "Removing intermediate container 61c97c3ab68d\n",
      " ---> 31f9e830d132\n",
      "Step 4/5 : COPY train.py .\n",
      " ---> 285927c51154\n",
      "Step 5/5 : ENTRYPOINT [\"python\", \"train.py\"]\n",
      " ---> Running in 1cfb1f071243\n",
      "Removing intermediate container 1cfb1f071243\n",
      " ---> 88f281df9da7\n",
      "Successfully built 88f281df9da7\n",
      "Successfully tagged gcr.io/zeta-rush-341516/trainer_image:latest\n",
      "PUSH\n",
      "Pushing gcr.io/zeta-rush-341516/trainer_image:latest\n",
      "The push refers to repository [gcr.io/zeta-rush-341516/trainer_image]\n",
      "70177a8e64c4: Preparing\n",
      "38285ea22fd0: Preparing\n",
      "54735eb374e9: Preparing\n",
      "b638c3dd1b30: Preparing\n",
      "b107f55e5b0f: Preparing\n",
      "804eb8042115: Preparing\n",
      "6535e7ceaeea: Preparing\n",
      "589d659ee3aa: Preparing\n",
      "5430153ced2f: Preparing\n",
      "8763b90e8bce: Preparing\n",
      "e686d686dc1d: Preparing\n",
      "3b98c56dcfc0: Preparing\n",
      "243bdd09476c: Preparing\n",
      "39e0384be1ed: Preparing\n",
      "ae1f0864cc76: Preparing\n",
      "f1c924e4876e: Preparing\n",
      "5f70bf18a086: Preparing\n",
      "9aa8282950fe: Preparing\n",
      "4a1b0b19050d: Preparing\n",
      "c9ffb453bec5: Preparing\n",
      "36ffdceb4c77: Preparing\n",
      "804eb8042115: Waiting\n",
      "6535e7ceaeea: Waiting\n",
      "589d659ee3aa: Waiting\n",
      "243bdd09476c: Waiting\n",
      "39e0384be1ed: Waiting\n",
      "ae1f0864cc76: Waiting\n",
      "5430153ced2f: Waiting\n",
      "8763b90e8bce: Waiting\n",
      "e686d686dc1d: Waiting\n",
      "3b98c56dcfc0: Waiting\n",
      "f1c924e4876e: Waiting\n",
      "5f70bf18a086: Waiting\n",
      "9aa8282950fe: Waiting\n",
      "4a1b0b19050d: Waiting\n",
      "c9ffb453bec5: Waiting\n",
      "36ffdceb4c77: Waiting\n",
      "b638c3dd1b30: Layer already exists\n",
      "b107f55e5b0f: Layer already exists\n",
      "804eb8042115: Layer already exists\n",
      "6535e7ceaeea: Layer already exists\n",
      "5430153ced2f: Layer already exists\n",
      "589d659ee3aa: Layer already exists\n",
      "8763b90e8bce: Layer already exists\n",
      "e686d686dc1d: Layer already exists\n",
      "3b98c56dcfc0: Layer already exists\n",
      "243bdd09476c: Layer already exists\n",
      "39e0384be1ed: Layer already exists\n",
      "ae1f0864cc76: Layer already exists\n",
      "f1c924e4876e: Layer already exists\n",
      "5f70bf18a086: Layer already exists\n",
      "9aa8282950fe: Layer already exists\n",
      "4a1b0b19050d: Layer already exists\n",
      "c9ffb453bec5: Layer already exists\n",
      "36ffdceb4c77: Layer already exists\n",
      "38285ea22fd0: Pushed\n",
      "70177a8e64c4: Pushed\n",
      "54735eb374e9: Pushed\n",
      "latest: digest: sha256:74ded9a30af1a1b3ffe7de640418b9b0ae4d870b89e939ec6422e46e89978236 size: 4707\n",
      "DONE\n",
      "--------------------------------------------------------------------------------\n",
      "ID                                    CREATE_TIME                DURATION  SOURCE                                                                                          IMAGES                                           STATUS\n",
      "3d083302-0757-42da-a50a-341705ff8e6b  2022-03-17T00:46:19+00:00  2M8S      gs://zeta-rush-341516_cloudbuild/source/1647477979.084049-6af7f304c194456c88a30a32f6ef1f0f.tgz  gcr.io/zeta-rush-341516/trainer_image (+1 more)  SUCCESS\n"
     ]
    }
   ],
   "source": [
    "!gcloud builds submit --tag $IMAGE_URI $TRAINING_APP_FOLDER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72a0bcb-b068-42a3-822e-968bf237e83e",
   "metadata": {},
   "source": [
    "__Submit an AI Platform hyperparameter tuning job__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "981307a3-2be4-402d-95ad-3a2567c8ed4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job [JOB_20220317_004937] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs describe JOB_20220317_004937\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs stream-logs JOB_20220317_004937\n",
      "jobId: JOB_20220317_004937\n",
      "state: QUEUED\n"
     ]
    }
   ],
   "source": [
    "JOB_NAME = \"JOB_{}\".format(time.strftime(\"%Y%m%d_%H%M%S\"))\n",
    "JOB_DIR = \"{}/{}\".format(JOB_DIR_ROOT, JOB_NAME)\n",
    "SCALE_TIER = \"BASIC\"\n",
    "\n",
    "!gcloud ai-platform jobs submit training $JOB_NAME \\\n",
    "--region=$REGION \\\n",
    "--job-dir=$JOB_DIR \\\n",
    "--master-image-uri=$IMAGE_URI \\\n",
    "--scale-tier=$SCALE_TIER \\\n",
    "--config $TRAINING_APP_FOLDER/hptuning_config.yaml \\\n",
    "-- \\\n",
    "--training_dataset_path=$TRAINING_FILE_PATH \\\n",
    "--validation_dataset_path=$VALIDATION_FILE_PATH \\\n",
    "--hptune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e080e21a-aae0-442c-bef0-14eec3972817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'JOB_20220317_004937'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JOB_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ba44e12-3b23-477d-9ab5-8ba4ec7c43fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "createTime: '2022-03-17T00:49:39Z'\n",
      "etag: v-ELqiuttJU=\n",
      "jobId: JOB_20220317_004937\n",
      "jobPosition: '0'\n",
      "startTime: '2022-03-17T00:49:43Z'\n",
      "state: RUNNING\n",
      "trainingInput:\n",
      "  args:\n",
      "  - --training_dataset_path=gs://mlops-youness/data/training/dataset.csv\n",
      "  - --validation_dataset_path=gs://mlops-youness/data/validation/dataset.csv\n",
      "  - --hptune\n",
      "  hyperparameters:\n",
      "    enableTrialEarlyStopping: true\n",
      "    goal: MAXIMIZE\n",
      "    hyperparameterMetricTag: accuracy\n",
      "    maxParallelTrials: 2\n",
      "    maxTrials: 4\n",
      "    params:\n",
      "    - discreteValues:\n",
      "      - 200.0\n",
      "      - 500.0\n",
      "      parameterName: max_iter\n",
      "      type: DISCRETE\n",
      "    - maxValue: 0.001\n",
      "      minValue: 1e-05\n",
      "      parameterName: alpha\n",
      "      scaleType: UNIT_LINEAR_SCALE\n",
      "      type: DOUBLE\n",
      "  jobDir: gs://mlops-youness/jobs/JOB_20220317_004937\n",
      "  masterConfig:\n",
      "    imageUri: gcr.io/zeta-rush-341516/trainer_image:latest\n",
      "  region: us-central1\n",
      "trainingOutput:\n",
      "  hyperparameterMetricTag: accuracy\n",
      "  isHyperparameterTuningJob: true\n",
      "\n",
      "View job in the Cloud Console at:\n",
      "https://console.cloud.google.com/mlengine/jobs/JOB_20220317_004937?project=zeta-rush-341516\n",
      "\n",
      "View logs at:\n",
      "https://console.cloud.google.com/logs?resource=ml_job%2Fjob_id%2FJOB_20220317_004937&project=zeta-rush-341516\n"
     ]
    }
   ],
   "source": [
    "!gcloud ai-platform jobs describe $JOB_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e823f5fc-0ddb-43c5-a045-443b3ea0e661",
   "metadata": {},
   "source": [
    "__Retrieve HP-tuning results__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6bb67450-6b05-42bd-8f5f-8829950ee648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'jobId': 'JOB_20220317_004937',\n",
       " 'trainingInput': {'args': ['--training_dataset_path=gs://mlops-youness/data/training/dataset.csv',\n",
       "   '--validation_dataset_path=gs://mlops-youness/data/validation/dataset.csv',\n",
       "   '--hptune'],\n",
       "  'hyperparameters': {'goal': 'MAXIMIZE',\n",
       "   'params': [{'parameterName': 'max_iter',\n",
       "     'type': 'DISCRETE',\n",
       "     'discreteValues': [200, 500]},\n",
       "    {'parameterName': 'alpha',\n",
       "     'minValue': 1e-05,\n",
       "     'maxValue': 0.001,\n",
       "     'type': 'DOUBLE',\n",
       "     'scaleType': 'UNIT_LINEAR_SCALE'}],\n",
       "   'maxTrials': 4,\n",
       "   'maxParallelTrials': 2,\n",
       "   'hyperparameterMetricTag': 'accuracy',\n",
       "   'enableTrialEarlyStopping': True},\n",
       "  'region': 'us-central1',\n",
       "  'jobDir': 'gs://mlops-youness/jobs/JOB_20220317_004937',\n",
       "  'masterConfig': {'imageUri': 'gcr.io/zeta-rush-341516/trainer_image:latest'}},\n",
       " 'createTime': '2022-03-17T00:49:39Z',\n",
       " 'startTime': '2022-03-17T00:49:43Z',\n",
       " 'endTime': '2022-03-17T01:06:51Z',\n",
       " 'state': 'SUCCEEDED',\n",
       " 'trainingOutput': {'completedTrialCount': '4',\n",
       "  'trials': [{'trialId': '2',\n",
       "    'hyperparameters': {'alpha': '0.00028772843036299335', 'max_iter': '500'},\n",
       "    'finalMetric': {'trainingStep': '1', 'objectiveValue': 0.7068930459536397},\n",
       "    'startTime': '2022-03-17T00:49:47.331239063Z',\n",
       "    'endTime': '2022-03-17T00:57:14Z',\n",
       "    'state': 'SUCCEEDED'},\n",
       "   {'trialId': '3',\n",
       "    'hyperparameters': {'alpha': '0.00026810459158081777', 'max_iter': '500'},\n",
       "    'finalMetric': {'trainingStep': '1', 'objectiveValue': 0.7038430256201708},\n",
       "    'startTime': '2022-03-17T00:58:30.757994227Z',\n",
       "    'endTime': '2022-03-17T01:05:58Z',\n",
       "    'state': 'SUCCEEDED'},\n",
       "   {'trialId': '1',\n",
       "    'hyperparameters': {'alpha': '0.000505', 'max_iter': '500'},\n",
       "    'finalMetric': {'trainingStep': '1', 'objectiveValue': 0.7019113460756405},\n",
       "    'startTime': '2022-03-17T00:49:47.331127623Z',\n",
       "    'endTime': '2022-03-17T00:57:15Z',\n",
       "    'state': 'SUCCEEDED'},\n",
       "   {'trialId': '4',\n",
       "    'hyperparameters': {'alpha': '0.00033043992941823614', 'max_iter': '500'},\n",
       "    'finalMetric': {'trainingStep': '1', 'objectiveValue': 0.7003863359089061},\n",
       "    'startTime': '2022-03-17T00:58:30.757770717Z',\n",
       "    'endTime': '2022-03-17T01:05:59Z',\n",
       "    'state': 'SUCCEEDED'}],\n",
       "  'consumedMLUnits': 0.26,\n",
       "  'isHyperparameterTuningJob': True,\n",
       "  'hyperparameterMetricTag': 'accuracy'},\n",
       " 'etag': 'nfN/n6Dbwj4=',\n",
       " 'jobPosition': '0'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml = discovery.build('ml', 'v1')\n",
    "\n",
    "job_id = 'projects/{}/jobs/{}'.format(PROJECT_ID, JOB_NAME)\n",
    "request = ml.projects().jobs().get(name=job_id)\n",
    "\n",
    "try:\n",
    "    response = request.execute()\n",
    "except errors.HttpError as err:\n",
    "    print(err)\n",
    "except:\n",
    "    print(\"Unexpected error\")\n",
    "    \n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7dfcd4e8-fd98-4feb-9ca8-97943dc49b1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'trialId': '2',\n",
       " 'hyperparameters': {'alpha': '0.00028772843036299335', 'max_iter': '500'},\n",
       " 'finalMetric': {'trainingStep': '1', 'objectiveValue': 0.7068930459536397},\n",
       " 'startTime': '2022-03-17T00:49:47.331239063Z',\n",
       " 'endTime': '2022-03-17T00:57:14Z',\n",
       " 'state': 'SUCCEEDED'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['trainingOutput']['trials'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d256ccd8-25ba-4a1b-a0f2-6816bd13b5d3",
   "metadata": {},
   "source": [
    "__Retrain the model with the best hyperparameters__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a19ba43a-b952-4ca8-afe5-d3feedc7a3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = response['trainingOutput']['trials'][0]['hyperparameters']['alpha']\n",
    "max_iter = response['trainingOutput']['trials'][0]['hyperparameters']['max_iter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e148d5bd-ac8c-47b7-b06e-80cff27a2d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job [JOB_20220317_012710] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs describe JOB_20220317_012710\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs stream-logs JOB_20220317_012710\n",
      "jobId: JOB_20220317_012710\n",
      "state: QUEUED\n"
     ]
    }
   ],
   "source": [
    "JOB_NAME = \"JOB_{}\".format(time.strftime(\"%Y%m%d_%H%M%S\"))\n",
    "JOB_DIR = \"{}/{}\".format(JOB_DIR_ROOT, JOB_NAME)\n",
    "SCALE_TIER = \"BASIC\"\n",
    "\n",
    "!gcloud ai-platform jobs submit training $JOB_NAME \\\n",
    "--region=$REGION \\\n",
    "--job-dir=$JOB_DIR \\\n",
    "--master-image-uri=$IMAGE_URI \\\n",
    "--scale-tier=$SCALE_TIER \\\n",
    "-- \\\n",
    "--training_dataset_path=$TRAINING_FILE_PATH \\\n",
    "--validation_dataset_path=$VALIDATION_FILE_PATH \\\n",
    "--alpha=$alpha \\\n",
    "--max_iter=$max_iter \\\n",
    "--nohptune\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "900b164c-bef6-4921-a848-34d83f59f073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "createTime: '2022-03-17T01:27:11Z'\n",
      "etag: AkwfjmR3dHQ=\n",
      "jobId: JOB_20220317_012710\n",
      "jobPosition: '0'\n",
      "startTime: '2022-03-17T01:29:06Z'\n",
      "state: RUNNING\n",
      "trainingInput:\n",
      "  args:\n",
      "  - --training_dataset_path=gs://mlops-youness/data/training/dataset.csv\n",
      "  - --validation_dataset_path=gs://mlops-youness/data/validation/dataset.csv\n",
      "  - --alpha=0.00028772843036299335\n",
      "  - --max_iter=500\n",
      "  - --nohptune\n",
      "  jobDir: gs://mlops-youness/jobs/JOB_20220317_012710\n",
      "  masterConfig:\n",
      "    imageUri: gcr.io/zeta-rush-341516/trainer_image:latest\n",
      "  region: us-central1\n",
      "trainingOutput: {}\n",
      "\n",
      "View job in the Cloud Console at:\n",
      "https://console.cloud.google.com/mlengine/jobs/JOB_20220317_012710?project=zeta-rush-341516\n",
      "\n",
      "View logs at:\n",
      "https://console.cloud.google.com/logs?resource=ml_job%2Fjob_id%2FJOB_20220317_012710&project=zeta-rush-341516\n"
     ]
    }
   ],
   "source": [
    "!gcloud ai-platform jobs describe $JOB_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "efe297ac-c0fb-4547-b853-6e7edce82e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://mlops-youness/jobs/JOB_20220317_012710/model.pkl\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls $JOB_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bed5b4c-c39d-411e-83c0-5ac549111095",
   "metadata": {},
   "source": [
    "Deploy the model to AI Platform Prediction\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7261c782-9d56-4c93-8fd7-e5bee5a6bfeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://ml.googleapis.com/]\n",
      "Created ai platform model [projects/zeta-rush-341516/models/forest_cover_classifier].\n"
     ]
    }
   ],
   "source": [
    "model_name = 'forest_cover_classifier'\n",
    "labels = \"task=classifier,domain=forestry\"\n",
    "\n",
    "!gcloud ai-platform models create  $model_name \\\n",
    " --regions=$REGION \\\n",
    " --labels=$labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19f3214-c2d8-48ab-8206-220ad9fa3bfb",
   "metadata": {},
   "source": [
    "__Create a model version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "374b1163-7707-4b00-b25d-fa02664dd621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://ml.googleapis.com/]\n",
      "Creating version (this might take a few minutes)......done.                    \n"
     ]
    }
   ],
   "source": [
    "model_version = 'v01'\n",
    "\n",
    "!gcloud ai-platform versions create {model_version} \\\n",
    " --model={model_name} \\\n",
    " --origin=$JOB_DIR \\\n",
    " --runtime-version=1.15 \\\n",
    " --framework=scikit-learn \\\n",
    " --python-version=3.7\\\n",
    " --region global"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead5c9cd-988e-46e8-bf11-12123bbc0c93",
   "metadata": {},
   "source": [
    "__Serve predictions__ : Prepare the input file with JSON formated instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4c32d0aa-f254-4592-8cf8-d6c8f21a497f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = 'serving_instances.json'\n",
    "\n",
    "with open(input_file, 'w') as f:\n",
    "    for index, row in X_validation.head().iterrows():\n",
    "        f.write(json.dumps(list(row.values)))\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c5787273-c98d-455c-a650-6ed2ce5d12c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2841.0, 45.0, 0.0, 644.0, 282.0, 1376.0, 218.0, 237.0, 156.0, 1003.0, \"Commanche\", \"C4758\"]\n",
      "[2494.0, 180.0, 0.0, 0.0, 0.0, 819.0, 219.0, 238.0, 157.0, 5531.0, \"Rawah\", \"C6101\"]\n",
      "[3153.0, 90.0, 0.0, 335.0, 11.0, 5842.0, 219.0, 237.0, 155.0, 930.0, \"Rawah\", \"C7101\"]\n",
      "[3021.0, 90.0, 0.0, 42.0, 1.0, 4389.0, 219.0, 237.0, 155.0, 902.0, \"Rawah\", \"C7745\"]\n",
      "[2916.0, 0.0, 0.0, 0.0, 0.0, 4562.0, 218.0, 238.0, 156.0, 5442.0, \"Rawah\", \"C7745\"]\n"
     ]
    }
   ],
   "source": [
    "!cat $input_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7daa4d1c-87d3-412e-82d7-2d9ea63785e5",
   "metadata": {},
   "source": [
    "__Invoke the model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e9daaf48-f8f1-4276-9d8b-5f47504fb5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://ml.googleapis.com/]\n",
      "[1, 1, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "!gcloud ai-platform predict \\\n",
    "--model $model_name \\\n",
    "--version $model_version \\\n",
    "--json-instances $input_file\\\n",
    "--region global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ba8b99-2137-45d4-9541-7fa210ecd114",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-10.m90",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-10:m90"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
