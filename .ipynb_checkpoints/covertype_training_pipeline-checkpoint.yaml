apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: covertype-classifier-training-
  annotations: {pipelines.kubeflow.org/kfp_sdk_version: 1.8.11, pipelines.kubeflow.org/pipeline_compilation_time: '2022-03-22T19:23:32.606049',
    pipelines.kubeflow.org/pipeline_spec: '{"description": "The pipeline training
      and deploying the Covertype classifierpipeline_yaml", "inputs": [{"name": "project_id"},
      {"name": "region"}, {"name": "source_table_name"}, {"name": "gcs_root"}, {"name":
      "dataset_id"}, {"name": "evaluation_metric_name"}, {"name": "evaluation_metric_threshold"},
      {"name": "model_id"}, {"name": "version_id"}, {"name": "replace_existing_version"},
      {"default": "\n{\n    \"hyperparameters\":  {\n        \"goal\": \"MAXIMIZE\",\n        \"maxTrials\":
      6,\n        \"maxParallelTrials\": 3,\n        \"hyperparameterMetricTag\":
      \"accuracy\",\n        \"enableTrialEarlyStopping\": True,\n        \"params\":
      [\n            {\n                \"parameterName\": \"max_iter\",\n                \"type\":
      \"DISCRETE\",\n                \"discreteValues\": [500, 1000]\n            },\n            {\n                \"parameterName\":
      \"alpha\",\n                \"type\": \"DOUBLE\",\n                \"minValue\":
      0.0001,\n                \"maxValue\": 0.001,\n                \"scaleType\":
      \"UNIT_LINEAR_SCALE\"\n            }\n        ]\n    }\n}\n", "name": "hypertune_settings",
      "optional": true}, {"default": "US", "name": "dataset_location", "optional":
      true}], "name": "Covertype Classifier Training"}'}
  labels: {pipelines.kubeflow.org/kfp_sdk_version: 1.8.11}
spec:
  entrypoint: covertype-classifier-training
  templates:
  - name: bigquery-query
    container:
      args:
      - --ui_metadata_path
      - /tmp/outputs/MLPipeline_UI_metadata/data
      - kfp_component.google.bigquery
      - query
      - --query
      - "\n         SELECT *\n         FROM \n             `{{inputs.parameters.source_table_name}}`\
        \ AS cover\n         WHERE \n         MOD(ABS(FARM_FINGERPRINT(TO_JSON_STRING(cover))),\
        \ 10) IN (1, 2, 3, 4)\n         "
      - --project_id
      - '{{inputs.parameters.project_id}}'
      - --dataset_id
      - '{{inputs.parameters.dataset_id}}'
      - --table_id
      - ''
      - --dataset_location
      - '{{inputs.parameters.dataset_location}}'
      - --output_gcs_path
      - '{{inputs.parameters.gcs_root}}/datasets/training/data.csv'
      - --job_config
      - ''
      command: []
      env:
      - {name: KFP_POD_NAME, value: '{{pod.name}}'}
      - name: KFP_POD_NAME
        valueFrom:
          fieldRef: {fieldPath: metadata.name}
      - name: KFP_POD_UID
        valueFrom:
          fieldRef: {fieldPath: metadata.uid}
      - name: KFP_NAMESPACE
        valueFrom:
          fieldRef: {fieldPath: metadata.namespace}
      - name: WORKFLOW_ID
        valueFrom:
          fieldRef: {fieldPath: 'metadata.labels[''workflows.argoproj.io/workflow'']'}
      - name: KFP_RUN_ID
        valueFrom:
          fieldRef: {fieldPath: 'metadata.labels[''pipeline/runid'']'}
      - name: ENABLE_CACHING
        valueFrom:
          fieldRef: {fieldPath: 'metadata.labels[''pipelines.kubeflow.org/enable_caching'']'}
      image: gcr.io/ml-pipeline/ml-pipeline-gcp:e66dcb18607406330f953bf99b04fe7c3ed1a4a8
    inputs:
      parameters:
      - {name: dataset_id}
      - {name: dataset_location}
      - {name: gcs_root}
      - {name: project_id}
      - {name: source_table_name}
    outputs:
      parameters:
      - name: bigquery-query-output_gcs_path
        valueFrom: {path: /tmp/kfp/output/bigquery/query-output-path.txt}
      artifacts:
      - {name: mlpipeline-ui-metadata, path: /tmp/outputs/MLPipeline_UI_metadata/data}
      - {name: bigquery-query-output_gcs_path, path: /tmp/kfp/output/bigquery/query-output-path.txt}
    metadata:
      labels:
        add-pod-env: "true"
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.11
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/enable_caching: "true"
      annotations: {pipelines.kubeflow.org/component_spec: '{"description": "A Kubeflow
          Pipeline component to submit a query to Google Cloud Bigquery \nservice
          and dump outputs to a Google Cloud Storage blob. \n", "implementation":
          {"container": {"args": ["--ui_metadata_path", {"outputPath": "MLPipeline
          UI metadata"}, "kfp_component.google.bigquery", "query", "--query", {"inputValue":
          "query"}, "--project_id", {"inputValue": "project_id"}, "--dataset_id",
          {"inputValue": "dataset_id"}, "--table_id", {"inputValue": "table_id"},
          "--dataset_location", {"inputValue": "dataset_location"}, "--output_gcs_path",
          {"inputValue": "output_gcs_path"}, "--job_config", {"inputValue": "job_config"}],
          "env": {"KFP_POD_NAME": "{{pod.name}}"}, "fileOutputs": {"output_gcs_path":
          "/tmp/kfp/output/bigquery/query-output-path.txt"}, "image": "gcr.io/ml-pipeline/ml-pipeline-gcp:e66dcb18607406330f953bf99b04fe7c3ed1a4a8"}},
          "inputs": [{"description": "The query used by Bigquery service to fetch
          the results.", "name": "query", "type": "String"}, {"description": "The
          project to execute the query job.", "name": "project_id", "type": "GCPProjectID"},
          {"default": "", "description": "The ID of the persistent dataset to keep
          the results of the query.", "name": "dataset_id", "type": "String"}, {"default":
          "", "description": "The ID of the table to keep the results of the query.
          If absent, the operation will generate a random id for the table.", "name":
          "table_id", "type": "String"}, {"default": "", "description": "The path
          to the Cloud Storage bucket to store the query output.", "name": "output_gcs_path",
          "type": "GCSPath"}, {"default": "US", "description": "The location to create
          the dataset. Defaults to `US`.", "name": "dataset_location", "type": "String"},
          {"default": "", "description": "The full config spec for the query job.See  [QueryJobConfig](https://googleapis.github.io/google-cloud-python/latest/bigquery/generated/google.cloud.bigquery.job.QueryJobConfig.html#google.cloud.bigquery.job.QueryJobConfig)  for
          details.", "name": "job_config", "type": "Dict"}], "metadata": {"labels":
          {"add-pod-env": "true"}}, "name": "Bigquery - Query", "outputs": [{"description":
          "The path to the Cloud Storage bucket containing the query output in CSV
          format.", "name": "output_gcs_path", "type": "GCSPath"}, {"name": "MLPipeline
          UI metadata", "type": "UI metadata"}]}', pipelines.kubeflow.org/component_ref: '{"digest":
          "3ef96c143973e87e57c04b672e4fb757170871f3353ac2fb6c1485d5fbe3518a", "name":
          "bigquery/query", "url": "https://raw.githubusercontent.com/kubeflow/pipelines/0.2.5/components/gcp/bigquery/query/component.yaml"}',
        pipelines.kubeflow.org/arguments.parameters: '{"dataset_id": "{{inputs.parameters.dataset_id}}",
          "dataset_location": "{{inputs.parameters.dataset_location}}", "job_config":
          "", "output_gcs_path": "{{inputs.parameters.gcs_root}}/datasets/training/data.csv",
          "project_id": "{{inputs.parameters.project_id}}", "query": "\n         SELECT
          *\n         FROM \n             `{{inputs.parameters.source_table_name}}`
          AS cover\n         WHERE \n         MOD(ABS(FARM_FINGERPRINT(TO_JSON_STRING(cover))),
          10) IN (1, 2, 3, 4)\n         ", "table_id": ""}'}
  - name: bigquery-query-2
    container:
      args:
      - --ui_metadata_path
      - /tmp/outputs/MLPipeline_UI_metadata/data
      - kfp_component.google.bigquery
      - query
      - --query
      - "\n         SELECT *\n         FROM \n             `{{inputs.parameters.source_table_name}}`\
        \ AS cover\n         WHERE \n         MOD(ABS(FARM_FINGERPRINT(TO_JSON_STRING(cover))),\
        \ 10) IN (8)\n         "
      - --project_id
      - '{{inputs.parameters.project_id}}'
      - --dataset_id
      - '{{inputs.parameters.dataset_id}}'
      - --table_id
      - ''
      - --dataset_location
      - '{{inputs.parameters.dataset_location}}'
      - --output_gcs_path
      - '{{inputs.parameters.gcs_root}}/datasets/validation/data.csv'
      - --job_config
      - ''
      command: []
      env:
      - {name: KFP_POD_NAME, value: '{{pod.name}}'}
      - name: KFP_POD_NAME
        valueFrom:
          fieldRef: {fieldPath: metadata.name}
      - name: KFP_POD_UID
        valueFrom:
          fieldRef: {fieldPath: metadata.uid}
      - name: KFP_NAMESPACE
        valueFrom:
          fieldRef: {fieldPath: metadata.namespace}
      - name: WORKFLOW_ID
        valueFrom:
          fieldRef: {fieldPath: 'metadata.labels[''workflows.argoproj.io/workflow'']'}
      - name: KFP_RUN_ID
        valueFrom:
          fieldRef: {fieldPath: 'metadata.labels[''pipeline/runid'']'}
      - name: ENABLE_CACHING
        valueFrom:
          fieldRef: {fieldPath: 'metadata.labels[''pipelines.kubeflow.org/enable_caching'']'}
      image: gcr.io/ml-pipeline/ml-pipeline-gcp:e66dcb18607406330f953bf99b04fe7c3ed1a4a8
    inputs:
      parameters:
      - {name: dataset_id}
      - {name: dataset_location}
      - {name: gcs_root}
      - {name: project_id}
      - {name: source_table_name}
    outputs:
      parameters:
      - name: bigquery-query-2-output_gcs_path
        valueFrom: {path: /tmp/kfp/output/bigquery/query-output-path.txt}
      artifacts:
      - {name: mlpipeline-ui-metadata, path: /tmp/outputs/MLPipeline_UI_metadata/data}
      - {name: bigquery-query-2-output_gcs_path, path: /tmp/kfp/output/bigquery/query-output-path.txt}
    metadata:
      labels:
        add-pod-env: "true"
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.11
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/enable_caching: "true"
      annotations: {pipelines.kubeflow.org/component_spec: '{"description": "A Kubeflow
          Pipeline component to submit a query to Google Cloud Bigquery \nservice
          and dump outputs to a Google Cloud Storage blob. \n", "implementation":
          {"container": {"args": ["--ui_metadata_path", {"outputPath": "MLPipeline
          UI metadata"}, "kfp_component.google.bigquery", "query", "--query", {"inputValue":
          "query"}, "--project_id", {"inputValue": "project_id"}, "--dataset_id",
          {"inputValue": "dataset_id"}, "--table_id", {"inputValue": "table_id"},
          "--dataset_location", {"inputValue": "dataset_location"}, "--output_gcs_path",
          {"inputValue": "output_gcs_path"}, "--job_config", {"inputValue": "job_config"}],
          "env": {"KFP_POD_NAME": "{{pod.name}}"}, "fileOutputs": {"output_gcs_path":
          "/tmp/kfp/output/bigquery/query-output-path.txt"}, "image": "gcr.io/ml-pipeline/ml-pipeline-gcp:e66dcb18607406330f953bf99b04fe7c3ed1a4a8"}},
          "inputs": [{"description": "The query used by Bigquery service to fetch
          the results.", "name": "query", "type": "String"}, {"description": "The
          project to execute the query job.", "name": "project_id", "type": "GCPProjectID"},
          {"default": "", "description": "The ID of the persistent dataset to keep
          the results of the query.", "name": "dataset_id", "type": "String"}, {"default":
          "", "description": "The ID of the table to keep the results of the query.
          If absent, the operation will generate a random id for the table.", "name":
          "table_id", "type": "String"}, {"default": "", "description": "The path
          to the Cloud Storage bucket to store the query output.", "name": "output_gcs_path",
          "type": "GCSPath"}, {"default": "US", "description": "The location to create
          the dataset. Defaults to `US`.", "name": "dataset_location", "type": "String"},
          {"default": "", "description": "The full config spec for the query job.See  [QueryJobConfig](https://googleapis.github.io/google-cloud-python/latest/bigquery/generated/google.cloud.bigquery.job.QueryJobConfig.html#google.cloud.bigquery.job.QueryJobConfig)  for
          details.", "name": "job_config", "type": "Dict"}], "metadata": {"labels":
          {"add-pod-env": "true"}}, "name": "Bigquery - Query", "outputs": [{"description":
          "The path to the Cloud Storage bucket containing the query output in CSV
          format.", "name": "output_gcs_path", "type": "GCSPath"}, {"name": "MLPipeline
          UI metadata", "type": "UI metadata"}]}', pipelines.kubeflow.org/component_ref: '{"digest":
          "3ef96c143973e87e57c04b672e4fb757170871f3353ac2fb6c1485d5fbe3518a", "name":
          "bigquery/query", "url": "https://raw.githubusercontent.com/kubeflow/pipelines/0.2.5/components/gcp/bigquery/query/component.yaml"}',
        pipelines.kubeflow.org/arguments.parameters: '{"dataset_id": "{{inputs.parameters.dataset_id}}",
          "dataset_location": "{{inputs.parameters.dataset_location}}", "job_config":
          "", "output_gcs_path": "{{inputs.parameters.gcs_root}}/datasets/validation/data.csv",
          "project_id": "{{inputs.parameters.project_id}}", "query": "\n         SELECT
          *\n         FROM \n             `{{inputs.parameters.source_table_name}}`
          AS cover\n         WHERE \n         MOD(ABS(FARM_FINGERPRINT(TO_JSON_STRING(cover))),
          10) IN (8)\n         ", "table_id": ""}'}
  - name: bigquery-query-3
    container:
      args:
      - --ui_metadata_path
      - /tmp/outputs/MLPipeline_UI_metadata/data
      - kfp_component.google.bigquery
      - query
      - --query
      - "\n         SELECT *\n         FROM \n             `{{inputs.parameters.source_table_name}}`\
        \ AS cover\n         WHERE \n         MOD(ABS(FARM_FINGERPRINT(TO_JSON_STRING(cover))),\
        \ 10) IN (9)\n         "
      - --project_id
      - '{{inputs.parameters.project_id}}'
      - --dataset_id
      - '{{inputs.parameters.dataset_id}}'
      - --table_id
      - ''
      - --dataset_location
      - '{{inputs.parameters.dataset_location}}'
      - --output_gcs_path
      - '{{inputs.parameters.gcs_root}}/datasets/testing/data.csv'
      - --job_config
      - ''
      command: []
      env:
      - {name: KFP_POD_NAME, value: '{{pod.name}}'}
      - name: KFP_POD_NAME
        valueFrom:
          fieldRef: {fieldPath: metadata.name}
      - name: KFP_POD_UID
        valueFrom:
          fieldRef: {fieldPath: metadata.uid}
      - name: KFP_NAMESPACE
        valueFrom:
          fieldRef: {fieldPath: metadata.namespace}
      - name: WORKFLOW_ID
        valueFrom:
          fieldRef: {fieldPath: 'metadata.labels[''workflows.argoproj.io/workflow'']'}
      - name: KFP_RUN_ID
        valueFrom:
          fieldRef: {fieldPath: 'metadata.labels[''pipeline/runid'']'}
      - name: ENABLE_CACHING
        valueFrom:
          fieldRef: {fieldPath: 'metadata.labels[''pipelines.kubeflow.org/enable_caching'']'}
      image: gcr.io/ml-pipeline/ml-pipeline-gcp:e66dcb18607406330f953bf99b04fe7c3ed1a4a8
    inputs:
      parameters:
      - {name: dataset_id}
      - {name: dataset_location}
      - {name: gcs_root}
      - {name: project_id}
      - {name: source_table_name}
    outputs:
      parameters:
      - name: bigquery-query-3-output_gcs_path
        valueFrom: {path: /tmp/kfp/output/bigquery/query-output-path.txt}
      artifacts:
      - {name: mlpipeline-ui-metadata, path: /tmp/outputs/MLPipeline_UI_metadata/data}
      - {name: bigquery-query-3-output_gcs_path, path: /tmp/kfp/output/bigquery/query-output-path.txt}
    metadata:
      labels:
        add-pod-env: "true"
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.11
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/enable_caching: "true"
      annotations: {pipelines.kubeflow.org/component_spec: '{"description": "A Kubeflow
          Pipeline component to submit a query to Google Cloud Bigquery \nservice
          and dump outputs to a Google Cloud Storage blob. \n", "implementation":
          {"container": {"args": ["--ui_metadata_path", {"outputPath": "MLPipeline
          UI metadata"}, "kfp_component.google.bigquery", "query", "--query", {"inputValue":
          "query"}, "--project_id", {"inputValue": "project_id"}, "--dataset_id",
          {"inputValue": "dataset_id"}, "--table_id", {"inputValue": "table_id"},
          "--dataset_location", {"inputValue": "dataset_location"}, "--output_gcs_path",
          {"inputValue": "output_gcs_path"}, "--job_config", {"inputValue": "job_config"}],
          "env": {"KFP_POD_NAME": "{{pod.name}}"}, "fileOutputs": {"output_gcs_path":
          "/tmp/kfp/output/bigquery/query-output-path.txt"}, "image": "gcr.io/ml-pipeline/ml-pipeline-gcp:e66dcb18607406330f953bf99b04fe7c3ed1a4a8"}},
          "inputs": [{"description": "The query used by Bigquery service to fetch
          the results.", "name": "query", "type": "String"}, {"description": "The
          project to execute the query job.", "name": "project_id", "type": "GCPProjectID"},
          {"default": "", "description": "The ID of the persistent dataset to keep
          the results of the query.", "name": "dataset_id", "type": "String"}, {"default":
          "", "description": "The ID of the table to keep the results of the query.
          If absent, the operation will generate a random id for the table.", "name":
          "table_id", "type": "String"}, {"default": "", "description": "The path
          to the Cloud Storage bucket to store the query output.", "name": "output_gcs_path",
          "type": "GCSPath"}, {"default": "US", "description": "The location to create
          the dataset. Defaults to `US`.", "name": "dataset_location", "type": "String"},
          {"default": "", "description": "The full config spec for the query job.See  [QueryJobConfig](https://googleapis.github.io/google-cloud-python/latest/bigquery/generated/google.cloud.bigquery.job.QueryJobConfig.html#google.cloud.bigquery.job.QueryJobConfig)  for
          details.", "name": "job_config", "type": "Dict"}], "metadata": {"labels":
          {"add-pod-env": "true"}}, "name": "Bigquery - Query", "outputs": [{"description":
          "The path to the Cloud Storage bucket containing the query output in CSV
          format.", "name": "output_gcs_path", "type": "GCSPath"}, {"name": "MLPipeline
          UI metadata", "type": "UI metadata"}]}', pipelines.kubeflow.org/component_ref: '{"digest":
          "3ef96c143973e87e57c04b672e4fb757170871f3353ac2fb6c1485d5fbe3518a", "name":
          "bigquery/query", "url": "https://raw.githubusercontent.com/kubeflow/pipelines/0.2.5/components/gcp/bigquery/query/component.yaml"}',
        pipelines.kubeflow.org/arguments.parameters: '{"dataset_id": "{{inputs.parameters.dataset_id}}",
          "dataset_location": "{{inputs.parameters.dataset_location}}", "job_config":
          "", "output_gcs_path": "{{inputs.parameters.gcs_root}}/datasets/testing/data.csv",
          "project_id": "{{inputs.parameters.project_id}}", "query": "\n         SELECT
          *\n         FROM \n             `{{inputs.parameters.source_table_name}}`
          AS cover\n         WHERE \n         MOD(ABS(FARM_FINGERPRINT(TO_JSON_STRING(cover))),
          10) IN (9)\n         ", "table_id": ""}'}
  - name: condition-1
    inputs:
      parameters:
      - {name: model_id}
      - {name: project_id}
      - {name: replace_existing_version}
      - {name: submitting-a-cloud-ml-training-job-as-a-pipeline-step-2-job_dir}
      - {name: version_id}
    dag:
      tasks:
      - name: deploying-a-trained-model-to-cloud-machine-learning-engine
        template: deploying-a-trained-model-to-cloud-machine-learning-engine
        arguments:
          parameters:
          - {name: model_id, value: '{{inputs.parameters.model_id}}'}
          - {name: project_id, value: '{{inputs.parameters.project_id}}'}
          - {name: replace_existing_version, value: '{{inputs.parameters.replace_existing_version}}'}
          - {name: submitting-a-cloud-ml-training-job-as-a-pipeline-step-2-job_dir,
            value: '{{inputs.parameters.submitting-a-cloud-ml-training-job-as-a-pipeline-step-2-job_dir}}'}
          - {name: version_id, value: '{{inputs.parameters.version_id}}'}
  - name: covertype-classifier-training
    inputs:
      parameters:
      - {name: dataset_id}
      - {name: dataset_location}
      - {name: evaluation_metric_name}
      - {name: evaluation_metric_threshold}
      - {name: gcs_root}
      - {name: hypertune_settings}
      - {name: model_id}
      - {name: project_id}
      - {name: region}
      - {name: replace_existing_version}
      - {name: source_table_name}
      - {name: version_id}
    dag:
      tasks:
      - name: bigquery-query
        template: bigquery-query
        arguments:
          parameters:
          - {name: dataset_id, value: '{{inputs.parameters.dataset_id}}'}
          - {name: dataset_location, value: '{{inputs.parameters.dataset_location}}'}
          - {name: gcs_root, value: '{{inputs.parameters.gcs_root}}'}
          - {name: project_id, value: '{{inputs.parameters.project_id}}'}
          - {name: source_table_name, value: '{{inputs.parameters.source_table_name}}'}
      - name: bigquery-query-2
        template: bigquery-query-2
        arguments:
          parameters:
          - {name: dataset_id, value: '{{inputs.parameters.dataset_id}}'}
          - {name: dataset_location, value: '{{inputs.parameters.dataset_location}}'}
          - {name: gcs_root, value: '{{inputs.parameters.gcs_root}}'}
          - {name: project_id, value: '{{inputs.parameters.project_id}}'}
          - {name: source_table_name, value: '{{inputs.parameters.source_table_name}}'}
      - name: bigquery-query-3
        template: bigquery-query-3
        arguments:
          parameters:
          - {name: dataset_id, value: '{{inputs.parameters.dataset_id}}'}
          - {name: dataset_location, value: '{{inputs.parameters.dataset_location}}'}
          - {name: gcs_root, value: '{{inputs.parameters.gcs_root}}'}
          - {name: project_id, value: '{{inputs.parameters.project_id}}'}
          - {name: source_table_name, value: '{{inputs.parameters.source_table_name}}'}
      - name: condition-1
        template: condition-1
        when: '{{tasks.evaluate-model.outputs.parameters.evaluate-model-metric_value}}
          > {{inputs.parameters.evaluation_metric_threshold}}'
        dependencies: [evaluate-model, submitting-a-cloud-ml-training-job-as-a-pipeline-step-2]
        arguments:
          parameters:
          - {name: model_id, value: '{{inputs.parameters.model_id}}'}
          - {name: project_id, value: '{{inputs.parameters.project_id}}'}
          - {name: replace_existing_version, value: '{{inputs.parameters.replace_existing_version}}'}
          - {name: submitting-a-cloud-ml-training-job-as-a-pipeline-step-2-job_dir,
            value: '{{tasks.submitting-a-cloud-ml-training-job-as-a-pipeline-step-2.outputs.parameters.submitting-a-cloud-ml-training-job-as-a-pipeline-step-2-job_dir}}'}
          - {name: version_id, value: '{{inputs.parameters.version_id}}'}
      - name: evaluate-model
        template: evaluate-model
        dependencies: [bigquery-query-3, submitting-a-cloud-ml-training-job-as-a-pipeline-step-2]
        arguments:
          parameters:
          - {name: bigquery-query-3-output_gcs_path, value: '{{tasks.bigquery-query-3.outputs.parameters.bigquery-query-3-output_gcs_path}}'}
          - {name: evaluation_metric_name, value: '{{inputs.parameters.evaluation_metric_name}}'}
          - {name: submitting-a-cloud-ml-training-job-as-a-pipeline-step-2-job_dir,
            value: '{{tasks.submitting-a-cloud-ml-training-job-as-a-pipeline-step-2.outputs.parameters.submitting-a-cloud-ml-training-job-as-a-pipeline-step-2-job_dir}}'}
      - name: retrieve-best-run
        template: retrieve-best-run
        dependencies: [submitting-a-cloud-ml-training-job-as-a-pipeline-step]
        arguments:
          parameters:
          - {name: project_id, value: '{{inputs.parameters.project_id}}'}
          - {name: submitting-a-cloud-ml-training-job-as-a-pipeline-step-job_id, value: '{{tasks.submitting-a-cloud-ml-training-job-as-a-pipeline-step.outputs.parameters.submitting-a-cloud-ml-training-job-as-a-pipeline-step-job_id}}'}
      - name: submitting-a-cloud-ml-training-job-as-a-pipeline-step
        template: submitting-a-cloud-ml-training-job-as-a-pipeline-step
        dependencies: [bigquery-query, bigquery-query-2]
        arguments:
          parameters:
          - {name: bigquery-query-2-output_gcs_path, value: '{{tasks.bigquery-query-2.outputs.parameters.bigquery-query-2-output_gcs_path}}'}
          - {name: bigquery-query-output_gcs_path, value: '{{tasks.bigquery-query.outputs.parameters.bigquery-query-output_gcs_path}}'}
          - {name: gcs_root, value: '{{inputs.parameters.gcs_root}}'}
          - {name: hypertune_settings, value: '{{inputs.parameters.hypertune_settings}}'}
          - {name: project_id, value: '{{inputs.parameters.project_id}}'}
          - {name: region, value: '{{inputs.parameters.region}}'}
      - name: submitting-a-cloud-ml-training-job-as-a-pipeline-step-2
        template: submitting-a-cloud-ml-training-job-as-a-pipeline-step-2
        dependencies: [bigquery-query, bigquery-query-2, retrieve-best-run]
        arguments:
          parameters:
          - {name: bigquery-query-2-output_gcs_path, value: '{{tasks.bigquery-query-2.outputs.parameters.bigquery-query-2-output_gcs_path}}'}
          - {name: bigquery-query-output_gcs_path, value: '{{tasks.bigquery-query.outputs.parameters.bigquery-query-output_gcs_path}}'}
          - {name: gcs_root, value: '{{inputs.parameters.gcs_root}}'}
          - {name: project_id, value: '{{inputs.parameters.project_id}}'}
          - {name: region, value: '{{inputs.parameters.region}}'}
          - {name: retrieve-best-run-alpha, value: '{{tasks.retrieve-best-run.outputs.parameters.retrieve-best-run-alpha}}'}
          - {name: retrieve-best-run-max_iter, value: '{{tasks.retrieve-best-run.outputs.parameters.retrieve-best-run-max_iter}}'}
  - name: deploying-a-trained-model-to-cloud-machine-learning-engine
    container:
      args:
      - --ui_metadata_path
      - /tmp/outputs/MLPipeline_UI_metadata/data
      - kfp_component.google.ml_engine
      - deploy
      - --model_uri
      - '{{inputs.parameters.submitting-a-cloud-ml-training-job-as-a-pipeline-step-2-job_dir}}'
      - --project_id
      - '{{inputs.parameters.project_id}}'
      - --model_id
      - '{{inputs.parameters.model_id}}'
      - --version_id
      - '{{inputs.parameters.version_id}}'
      - --runtime_version
      - '1.15'
      - --python_version
      - '3.7'
      - --model
      - ''
      - --version
      - ''
      - --replace_existing_version
      - '{{inputs.parameters.replace_existing_version}}'
      - --set_default
      - "False"
      - --wait_interval
      - '30'
      command: []
      env:
      - {name: KFP_POD_NAME, value: '{{pod.name}}'}
      - name: KFP_POD_NAME
        valueFrom:
          fieldRef: {fieldPath: metadata.name}
      - name: KFP_POD_UID
        valueFrom:
          fieldRef: {fieldPath: metadata.uid}
      - name: KFP_NAMESPACE
        valueFrom:
          fieldRef: {fieldPath: metadata.namespace}
      - name: WORKFLOW_ID
        valueFrom:
          fieldRef: {fieldPath: 'metadata.labels[''workflows.argoproj.io/workflow'']'}
      - name: KFP_RUN_ID
        valueFrom:
          fieldRef: {fieldPath: 'metadata.labels[''pipeline/runid'']'}
      - name: ENABLE_CACHING
        valueFrom:
          fieldRef: {fieldPath: 'metadata.labels[''pipelines.kubeflow.org/enable_caching'']'}
      image: gcr.io/ml-pipeline/ml-pipeline-gcp:e66dcb18607406330f953bf99b04fe7c3ed1a4a8
    inputs:
      parameters:
      - {name: model_id}
      - {name: project_id}
      - {name: replace_existing_version}
      - {name: submitting-a-cloud-ml-training-job-as-a-pipeline-step-2-job_dir}
      - {name: version_id}
    outputs:
      artifacts:
      - {name: mlpipeline-ui-metadata, path: /tmp/outputs/MLPipeline_UI_metadata/data}
      - {name: deploying-a-trained-model-to-cloud-machine-learning-engine-model_name,
        path: /tmp/kfp/output/ml_engine/model_name.txt}
      - {name: deploying-a-trained-model-to-cloud-machine-learning-engine-model_uri,
        path: /tmp/kfp/output/ml_engine/model_uri.txt}
      - {name: deploying-a-trained-model-to-cloud-machine-learning-engine-version_name,
        path: /tmp/kfp/output/ml_engine/version_name.txt}
    metadata:
      labels:
        add-pod-env: "true"
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.11
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/enable_caching: "true"
      annotations: {pipelines.kubeflow.org/component_spec: '{"description": "A Kubeflow
          Pipeline component to deploy a trained model from a Cloud Storage\npath
          to a Cloud Machine Learning Engine service.\n", "implementation": {"container":
          {"args": ["--ui_metadata_path", {"outputPath": "MLPipeline UI metadata"},
          "kfp_component.google.ml_engine", "deploy", "--model_uri", {"inputValue":
          "model_uri"}, "--project_id", {"inputValue": "project_id"}, "--model_id",
          {"inputValue": "model_id"}, "--version_id", {"inputValue": "version_id"},
          "--runtime_version", {"inputValue": "runtime_version"}, "--python_version",
          {"inputValue": "python_version"}, "--model", {"inputValue": "model"}, "--version",
          {"inputValue": "version"}, "--replace_existing_version", {"inputValue":
          "replace_existing_version"}, "--set_default", {"inputValue": "set_default"},
          "--wait_interval", {"inputValue": "wait_interval"}], "env": {"KFP_POD_NAME":
          "{{pod.name}}"}, "fileOutputs": {"model_name": "/tmp/kfp/output/ml_engine/model_name.txt",
          "model_uri": "/tmp/kfp/output/ml_engine/model_uri.txt", "version_name":
          "/tmp/kfp/output/ml_engine/version_name.txt"}, "image": "gcr.io/ml-pipeline/ml-pipeline-gcp:e66dcb18607406330f953bf99b04fe7c3ed1a4a8"}},
          "inputs": [{"description": "Required. The Cloud Storage URI which contains
          a model file. Commonly  used TF model search paths (export/exporter) will
          be used if they exist.", "name": "model_uri", "type": "GCSPath"}, {"description":
          "Required.The ID of the parent project of the serving model.", "name": "project_id",
          "type": "GCPProjectID"}, {"default": "", "description": "Optional. The user-specified
          name of the model. If it is not provided,  the operation uses a random name.",
          "name": "model_id", "type": "String"}, {"default": "", "description": "Optional.
          The user-specified name of the version. If it is not provided,  the operation
          uses a random name.", "name": "version_id", "type": "String"}, {"default":
          "", "description": "Optional. The [Cloud ML Engine runtime version](https://cloud.google.com/ml-engine/docs/tensorflow/runtime-version-list)
          to use for  this deployment. If it is not set, the Cloud ML Engine uses
          the default  stable version, 1.0.", "name": "runtime_version", "type": "String"},
          {"default": "", "description": "Optional. The version of Python used in
          the prediction. If it is not set,  the default version is `2.7`. Python
          `3.5` is available when the  runtime_version is set to `1.4` and above.
          Python `2.7` works with all  supported runtime versions.", "name": "python_version",
          "type": "String"}, {"default": "", "description": "Optional. The JSON payload
          of the new  [Model](https://cloud.google.com/ml-engine/reference/rest/v1/projects.models),
          if it does not exist.", "name": "model", "type": "Dict"}, {"default": "",
          "description": "Optional. The JSON payload of the new  [Version](https://cloud.google.com/ml-engine/reference/rest/v1/projects.models.versions).",
          "name": "version", "type": "Dict"}, {"default": "Fasle", "description":
          "A Boolean flag that indicates whether to replace existing version in case
          of conflict.", "name": "replace_existing_version", "type": "Bool"}, {"default":
          "False", "description": "A Boolean flag that indicates whether to set the
          new version as default version in the model.", "name": "set_default", "type":
          "Bool"}, {"default": "30", "description": "A time-interval to wait for in
          case the operation has a long run time.", "name": "wait_interval", "type":
          "Integer"}], "metadata": {"labels": {"add-pod-env": "true"}}, "name": "Deploying
          a trained model to Cloud Machine Learning Engine", "outputs": [{"description":
          "The Cloud Storage URI of the trained model.", "name": "model_uri", "type":
          "GCSPath"}, {"description": "The name of the deployed model.", "name": "model_name",
          "type": "String"}, {"description": "The name of the deployed version.",
          "name": "version_name", "type": "String"}, {"name": "MLPipeline UI metadata",
          "type": "UI metadata"}]}', pipelines.kubeflow.org/component_ref: '{"digest":
          "f5d0e68a796e39f9e672f4205644db1141e5267a8eb8594845c8abdb04018382", "name":
          "ml_engine/deploy", "url": "https://raw.githubusercontent.com/kubeflow/pipelines/0.2.5/components/gcp/ml_engine/deploy/component.yaml"}',
        pipelines.kubeflow.org/arguments.parameters: '{"model": "", "model_id": "{{inputs.parameters.model_id}}",
          "model_uri": "{{inputs.parameters.submitting-a-cloud-ml-training-job-as-a-pipeline-step-2-job_dir}}",
          "project_id": "{{inputs.parameters.project_id}}", "python_version": "3.7",
          "replace_existing_version": "{{inputs.parameters.replace_existing_version}}",
          "runtime_version": "1.15", "set_default": "False", "version": "", "version_id":
          "{{inputs.parameters.version_id}}", "wait_interval": "30"}'}
  - name: evaluate-model
    container:
      args: [--dataset-path, '{{inputs.parameters.bigquery-query-3-output_gcs_path}}',
        --model-path, '{{inputs.parameters.submitting-a-cloud-ml-training-job-as-a-pipeline-step-2-job_dir}}',
        --metric-name, '{{inputs.parameters.evaluation_metric_name}}', '----output-paths',
        /tmp/outputs/metric_name/data, /tmp/outputs/metric_value/data, /tmp/outputs/mlpipeline_metrics/data]
      command:
      - sh
      - -ec
      - |
        program_path=$(mktemp)
        printf "%s" "$0" > "$program_path"
        python3 -u "$program_path" "$@"
      - |
        def evaluate_model(dataset_path, model_path, metric_name):
            """Evaluates a trained sklearn model."""

            df_test = pd.read_csv(dataset_path)

            X_test = df_test.drop('Cover_Type', axis=1)
            y_test = df_test['Cover_Type']

            # Copy the model from GCS
            model_filename = 'model.pkl'
            gcs_model_filepath = '{}/{}'.format(model_path, model_filename)
            print(gcs_model_filepath)
            subprocess.check_call(['gsutil', 'cp', gcs_model_filepath, model_filename],
                                stderr=sys.stdout)

            with open(model_filename, 'rb') as model_file:
                model = pickle.load(model_file)

            y_hat = model.predict(X_test)

            if metric_name == 'accuracy':
                metric_value = accuracy_score(y_test, y_hat)
            elif metric_name == 'recall':
                metric_value = recall_score(y_test, y_hat)
            else:
                metric_name = 'N/A'
                metric_value = 0

            # Export the metric
            metrics = {
              'metrics': [{
                  'name': metric_name,
                  'numberValue': float(metric_value)
              }]
            }

            return (metric_name, metric_value, json.dumps(metrics))

        def _serialize_float(float_value: float) -> str:
            if isinstance(float_value, str):
                return float_value
            if not isinstance(float_value, (float, int)):
                raise TypeError('Value "{}" has type "{}" instead of float.'.format(
                    str(float_value), str(type(float_value))))
            return str(float_value)

        def _serialize_str(str_value: str) -> str:
            if not isinstance(str_value, str):
                raise TypeError('Value "{}" has type "{}" instead of str.'.format(
                    str(str_value), str(type(str_value))))
            return str_value

        import argparse
        _parser = argparse.ArgumentParser(prog='Evaluate model', description='Evaluates a trained sklearn model.')
        _parser.add_argument("--dataset-path", dest="dataset_path", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--model-path", dest="model_path", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--metric-name", dest="metric_name", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("----output-paths", dest="_output_paths", type=str, nargs=3)
        _parsed_args = vars(_parser.parse_args())
        _output_files = _parsed_args.pop("_output_paths", [])

        _outputs = evaluate_model(**_parsed_args)

        _output_serializers = [
            _serialize_str,
            _serialize_float,
            str,

        ]

        import os
        for idx, output_file in enumerate(_output_files):
            try:
                os.makedirs(os.path.dirname(output_file))
            except OSError:
                pass
            with open(output_file, 'w') as f:
                f.write(_output_serializers[idx](_outputs[idx]))
      image: gcr.io/zeta-rush-341516/base_image:latest
    inputs:
      parameters:
      - {name: bigquery-query-3-output_gcs_path}
      - {name: evaluation_metric_name}
      - {name: submitting-a-cloud-ml-training-job-as-a-pipeline-step-2-job_dir}
    outputs:
      parameters:
      - name: evaluate-model-metric_value
        valueFrom: {path: /tmp/outputs/metric_value/data}
      artifacts:
      - {name: mlpipeline-metrics, path: /tmp/outputs/mlpipeline_metrics/data}
      - {name: evaluate-model-metric_name, path: /tmp/outputs/metric_name/data}
      - {name: evaluate-model-metric_value, path: /tmp/outputs/metric_value/data}
    metadata:
      labels:
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.11
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/enable_caching: "true"
      annotations: {pipelines.kubeflow.org/component_spec: '{"description": "Evaluates
          a trained sklearn model.", "implementation": {"container": {"args": ["--dataset-path",
          {"inputValue": "dataset_path"}, "--model-path", {"inputValue": "model_path"},
          "--metric-name", {"inputValue": "metric_name"}, "----output-paths", {"outputPath":
          "metric_name"}, {"outputPath": "metric_value"}, {"outputPath": "mlpipeline_metrics"}],
          "command": ["sh", "-ec", "program_path=$(mktemp)\nprintf \"%s\" \"$0\" >
          \"$program_path\"\npython3 -u \"$program_path\" \"$@\"\n", "def evaluate_model(dataset_path,
          model_path, metric_name):\n    \"\"\"Evaluates a trained sklearn model.\"\"\"\n\n    df_test
          = pd.read_csv(dataset_path)\n\n    X_test = df_test.drop(''Cover_Type'',
          axis=1)\n    y_test = df_test[''Cover_Type'']\n\n    # Copy the model from
          GCS\n    model_filename = ''model.pkl''\n    gcs_model_filepath = ''{}/{}''.format(model_path,
          model_filename)\n    print(gcs_model_filepath)\n    subprocess.check_call([''gsutil'',
          ''cp'', gcs_model_filepath, model_filename],\n                        stderr=sys.stdout)\n\n    with
          open(model_filename, ''rb'') as model_file:\n        model = pickle.load(model_file)\n\n    y_hat
          = model.predict(X_test)\n\n    if metric_name == ''accuracy'':\n        metric_value
          = accuracy_score(y_test, y_hat)\n    elif metric_name == ''recall'':\n        metric_value
          = recall_score(y_test, y_hat)\n    else:\n        metric_name = ''N/A''\n        metric_value
          = 0\n\n    # Export the metric\n    metrics = {\n      ''metrics'': [{\n          ''name'':
          metric_name,\n          ''numberValue'': float(metric_value)\n      }]\n    }\n\n    return
          (metric_name, metric_value, json.dumps(metrics))\n\ndef _serialize_float(float_value:
          float) -> str:\n    if isinstance(float_value, str):\n        return float_value\n    if
          not isinstance(float_value, (float, int)):\n        raise TypeError(''Value
          \"{}\" has type \"{}\" instead of float.''.format(\n            str(float_value),
          str(type(float_value))))\n    return str(float_value)\n\ndef _serialize_str(str_value:
          str) -> str:\n    if not isinstance(str_value, str):\n        raise TypeError(''Value
          \"{}\" has type \"{}\" instead of str.''.format(\n            str(str_value),
          str(type(str_value))))\n    return str_value\n\nimport argparse\n_parser
          = argparse.ArgumentParser(prog=''Evaluate model'', description=''Evaluates
          a trained sklearn model.'')\n_parser.add_argument(\"--dataset-path\", dest=\"dataset_path\",
          type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--model-path\",
          dest=\"model_path\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--metric-name\",
          dest=\"metric_name\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"----output-paths\",
          dest=\"_output_paths\", type=str, nargs=3)\n_parsed_args = vars(_parser.parse_args())\n_output_files
          = _parsed_args.pop(\"_output_paths\", [])\n\n_outputs = evaluate_model(**_parsed_args)\n\n_output_serializers
          = [\n    _serialize_str,\n    _serialize_float,\n    str,\n\n]\n\nimport
          os\nfor idx, output_file in enumerate(_output_files):\n    try:\n        os.makedirs(os.path.dirname(output_file))\n    except
          OSError:\n        pass\n    with open(output_file, ''w'') as f:\n        f.write(_output_serializers[idx](_outputs[idx]))\n"],
          "image": "gcr.io/zeta-rush-341516/base_image:latest"}}, "inputs": [{"name":
          "dataset_path", "type": "String"}, {"name": "model_path", "type": "String"},
          {"name": "metric_name", "type": "String"}], "name": "Evaluate model", "outputs":
          [{"name": "metric_name", "type": "String"}, {"name": "metric_value", "type":
          "Float"}, {"name": "mlpipeline_metrics", "type": "Metrics"}]}', pipelines.kubeflow.org/component_ref: '{}',
        pipelines.kubeflow.org/arguments.parameters: '{"dataset_path": "{{inputs.parameters.bigquery-query-3-output_gcs_path}}",
          "metric_name": "{{inputs.parameters.evaluation_metric_name}}", "model_path":
          "{{inputs.parameters.submitting-a-cloud-ml-training-job-as-a-pipeline-step-2-job_dir}}"}'}
  - name: retrieve-best-run
    container:
      args: [--project-id, '{{inputs.parameters.project_id}}', --job-id, '{{inputs.parameters.submitting-a-cloud-ml-training-job-as-a-pipeline-step-job_id}}',
        '----output-paths', /tmp/outputs/metric_value/data, /tmp/outputs/alpha/data,
        /tmp/outputs/max_iter/data]
      command:
      - sh
      - -ec
      - |
        program_path=$(mktemp)
        printf "%s" "$0" > "$program_path"
        python3 -u "$program_path" "$@"
      - |
        def retrieve_best_run(project_id, job_id):
            """Retrieves the parameters of the best Hypertune run."""

            ml = discovery.build('ml', 'v1')

            job_name = 'projects/{}/jobs/{}'.format(project_id, job_id)
            request = ml.projects().jobs().get(name=job_name)

            try:
                response = request.execute()
            except errors.HttpError as err:
                print(err)
            except:
                print('Unexpected error')

            print(response)

            best_trial = response['trainingOutput']['trials'][0]

            metric_value = best_trial['finalMetric']['objectiveValue']
            alpha = float(best_trial['hyperparameters']['alpha'])
            max_iter = int(best_trial['hyperparameters']['max_iter'])

            return (metric_value, alpha, max_iter)

        def _serialize_float(float_value: float) -> str:
            if isinstance(float_value, str):
                return float_value
            if not isinstance(float_value, (float, int)):
                raise TypeError('Value "{}" has type "{}" instead of float.'.format(
                    str(float_value), str(type(float_value))))
            return str(float_value)

        def _serialize_int(int_value: int) -> str:
            if isinstance(int_value, str):
                return int_value
            if not isinstance(int_value, int):
                raise TypeError('Value "{}" has type "{}" instead of int.'.format(
                    str(int_value), str(type(int_value))))
            return str(int_value)

        import argparse
        _parser = argparse.ArgumentParser(prog='Retrieve best run', description='Retrieves the parameters of the best Hypertune run.')
        _parser.add_argument("--project-id", dest="project_id", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--job-id", dest="job_id", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("----output-paths", dest="_output_paths", type=str, nargs=3)
        _parsed_args = vars(_parser.parse_args())
        _output_files = _parsed_args.pop("_output_paths", [])

        _outputs = retrieve_best_run(**_parsed_args)

        _output_serializers = [
            _serialize_float,
            _serialize_float,
            _serialize_int,

        ]

        import os
        for idx, output_file in enumerate(_output_files):
            try:
                os.makedirs(os.path.dirname(output_file))
            except OSError:
                pass
            with open(output_file, 'w') as f:
                f.write(_output_serializers[idx](_outputs[idx]))
      image: gcr.io/zeta-rush-341516/base_image:latest
    inputs:
      parameters:
      - {name: project_id}
      - {name: submitting-a-cloud-ml-training-job-as-a-pipeline-step-job_id}
    outputs:
      parameters:
      - name: retrieve-best-run-alpha
        valueFrom: {path: /tmp/outputs/alpha/data}
      - name: retrieve-best-run-max_iter
        valueFrom: {path: /tmp/outputs/max_iter/data}
      artifacts:
      - {name: retrieve-best-run-alpha, path: /tmp/outputs/alpha/data}
      - {name: retrieve-best-run-max_iter, path: /tmp/outputs/max_iter/data}
      - {name: retrieve-best-run-metric_value, path: /tmp/outputs/metric_value/data}
    metadata:
      labels:
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.11
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/enable_caching: "true"
      annotations: {pipelines.kubeflow.org/component_spec: '{"description": "Retrieves
          the parameters of the best Hypertune run.", "implementation": {"container":
          {"args": ["--project-id", {"inputValue": "project_id"}, "--job-id", {"inputValue":
          "job_id"}, "----output-paths", {"outputPath": "metric_value"}, {"outputPath":
          "alpha"}, {"outputPath": "max_iter"}], "command": ["sh", "-ec", "program_path=$(mktemp)\nprintf
          \"%s\" \"$0\" > \"$program_path\"\npython3 -u \"$program_path\" \"$@\"\n",
          "def retrieve_best_run(project_id, job_id):\n    \"\"\"Retrieves the parameters
          of the best Hypertune run.\"\"\"\n\n    ml = discovery.build(''ml'', ''v1'')\n\n    job_name
          = ''projects/{}/jobs/{}''.format(project_id, job_id)\n    request = ml.projects().jobs().get(name=job_name)\n\n    try:\n        response
          = request.execute()\n    except errors.HttpError as err:\n        print(err)\n    except:\n        print(''Unexpected
          error'')\n\n    print(response)\n\n    best_trial = response[''trainingOutput''][''trials''][0]\n\n    metric_value
          = best_trial[''finalMetric''][''objectiveValue'']\n    alpha = float(best_trial[''hyperparameters''][''alpha''])\n    max_iter
          = int(best_trial[''hyperparameters''][''max_iter''])\n\n    return (metric_value,
          alpha, max_iter)\n\ndef _serialize_float(float_value: float) -> str:\n    if
          isinstance(float_value, str):\n        return float_value\n    if not isinstance(float_value,
          (float, int)):\n        raise TypeError(''Value \"{}\" has type \"{}\" instead
          of float.''.format(\n            str(float_value), str(type(float_value))))\n    return
          str(float_value)\n\ndef _serialize_int(int_value: int) -> str:\n    if isinstance(int_value,
          str):\n        return int_value\n    if not isinstance(int_value, int):\n        raise
          TypeError(''Value \"{}\" has type \"{}\" instead of int.''.format(\n            str(int_value),
          str(type(int_value))))\n    return str(int_value)\n\nimport argparse\n_parser
          = argparse.ArgumentParser(prog=''Retrieve best run'', description=''Retrieves
          the parameters of the best Hypertune run.'')\n_parser.add_argument(\"--project-id\",
          dest=\"project_id\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--job-id\",
          dest=\"job_id\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"----output-paths\",
          dest=\"_output_paths\", type=str, nargs=3)\n_parsed_args = vars(_parser.parse_args())\n_output_files
          = _parsed_args.pop(\"_output_paths\", [])\n\n_outputs = retrieve_best_run(**_parsed_args)\n\n_output_serializers
          = [\n    _serialize_float,\n    _serialize_float,\n    _serialize_int,\n\n]\n\nimport
          os\nfor idx, output_file in enumerate(_output_files):\n    try:\n        os.makedirs(os.path.dirname(output_file))\n    except
          OSError:\n        pass\n    with open(output_file, ''w'') as f:\n        f.write(_output_serializers[idx](_outputs[idx]))\n"],
          "image": "gcr.io/zeta-rush-341516/base_image:latest"}}, "inputs": [{"name":
          "project_id", "type": "String"}, {"name": "job_id", "type": "String"}],
          "name": "Retrieve best run", "outputs": [{"name": "metric_value", "type":
          "Float"}, {"name": "alpha", "type": "Float"}, {"name": "max_iter", "type":
          "Integer"}]}', pipelines.kubeflow.org/component_ref: '{}', pipelines.kubeflow.org/arguments.parameters: '{"job_id":
          "{{inputs.parameters.submitting-a-cloud-ml-training-job-as-a-pipeline-step-job_id}}",
          "project_id": "{{inputs.parameters.project_id}}"}'}
  - name: submitting-a-cloud-ml-training-job-as-a-pipeline-step
    container:
      args: [--ui_metadata_path, /tmp/outputs/MLPipeline_UI_metadata/data, kfp_component.google.ml_engine,
        train, --project_id, '{{inputs.parameters.project_id}}', --python_module,
        '', --package_uris, '', --region, '{{inputs.parameters.region}}', --args,
        '["--training_dataset_path", "{{inputs.parameters.bigquery-query-output_gcs_path}}",
          "--validation_dataset_path", "{{inputs.parameters.bigquery-query-2-output_gcs_path}}",
          "--hptune", "True"]', --job_dir, '{{inputs.parameters.gcs_root}}/jobdir/hypertune/{{workflow.uid}}',
        --python_version, '', --runtime_version, '', --master_image_uri, 'gcr.io/zeta-rush-341516/trainer_image:latest',
        --worker_image_uri, '', --training_input, '{{inputs.parameters.hypertune_settings}}',
        --job_id_prefix, '', --wait_interval, '30']
      command: []
      env:
      - {name: KFP_POD_NAME, value: '{{pod.name}}'}
      - name: KFP_POD_NAME
        valueFrom:
          fieldRef: {fieldPath: metadata.name}
      - name: KFP_POD_UID
        valueFrom:
          fieldRef: {fieldPath: metadata.uid}
      - name: KFP_NAMESPACE
        valueFrom:
          fieldRef: {fieldPath: metadata.namespace}
      - name: WORKFLOW_ID
        valueFrom:
          fieldRef: {fieldPath: 'metadata.labels[''workflows.argoproj.io/workflow'']'}
      - name: KFP_RUN_ID
        valueFrom:
          fieldRef: {fieldPath: 'metadata.labels[''pipeline/runid'']'}
      - name: ENABLE_CACHING
        valueFrom:
          fieldRef: {fieldPath: 'metadata.labels[''pipelines.kubeflow.org/enable_caching'']'}
      image: gcr.io/ml-pipeline/ml-pipeline-gcp:e66dcb18607406330f953bf99b04fe7c3ed1a4a8
    inputs:
      parameters:
      - {name: bigquery-query-2-output_gcs_path}
      - {name: bigquery-query-output_gcs_path}
      - {name: gcs_root}
      - {name: hypertune_settings}
      - {name: project_id}
      - {name: region}
    outputs:
      parameters:
      - name: submitting-a-cloud-ml-training-job-as-a-pipeline-step-job_id
        valueFrom: {path: /tmp/kfp/output/ml_engine/job_id.txt}
      artifacts:
      - {name: mlpipeline-ui-metadata, path: /tmp/outputs/MLPipeline_UI_metadata/data}
      - {name: submitting-a-cloud-ml-training-job-as-a-pipeline-step-job_dir, path: /tmp/kfp/output/ml_engine/job_dir.txt}
      - {name: submitting-a-cloud-ml-training-job-as-a-pipeline-step-job_id, path: /tmp/kfp/output/ml_engine/job_id.txt}
    metadata:
      labels:
        add-pod-env: "true"
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.11
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/enable_caching: "true"
      annotations: {pipelines.kubeflow.org/component_spec: '{"description": "A Kubeflow
          Pipeline component to submit a Cloud Machine Learning (Cloud ML) \nEngine
          training job as a step in a pipeline.\n", "implementation": {"container":
          {"args": ["--ui_metadata_path", {"outputPath": "MLPipeline UI metadata"},
          "kfp_component.google.ml_engine", "train", "--project_id", {"inputValue":
          "project_id"}, "--python_module", {"inputValue": "python_module"}, "--package_uris",
          {"inputValue": "package_uris"}, "--region", {"inputValue": "region"}, "--args",
          {"inputValue": "args"}, "--job_dir", {"inputValue": "job_dir"}, "--python_version",
          {"inputValue": "python_version"}, "--runtime_version", {"inputValue": "runtime_version"},
          "--master_image_uri", {"inputValue": "master_image_uri"}, "--worker_image_uri",
          {"inputValue": "worker_image_uri"}, "--training_input", {"inputValue": "training_input"},
          "--job_id_prefix", {"inputValue": "job_id_prefix"}, "--wait_interval", {"inputValue":
          "wait_interval"}], "env": {"KFP_POD_NAME": "{{pod.name}}"}, "fileOutputs":
          {"job_dir": "/tmp/kfp/output/ml_engine/job_dir.txt", "job_id": "/tmp/kfp/output/ml_engine/job_id.txt"},
          "image": "gcr.io/ml-pipeline/ml-pipeline-gcp:e66dcb18607406330f953bf99b04fe7c3ed1a4a8"}},
          "inputs": [{"description": "Required. The ID of the parent project of the
          job.", "name": "project_id", "type": "GCPProjectID"}, {"default": "", "description":
          "The Python module name to run after installing the packages.", "name":
          "python_module", "type": "String"}, {"default": "", "description": "The
          Cloud Storage location of the packages (that contain the training program  and
          any additional dependencies). The maximum number of package URIs is 100.",
          "name": "package_uris", "type": "List"}, {"default": "", "description":
          "The Compute Engine region in which the training job is run.", "name": "region",
          "type": "GCPRegion"}, {"default": "", "description": "The command line arguments
          to pass to the program.", "name": "args", "type": "List"}, {"default": "",
          "description": "A Cloud Storage path in which to store the training outputs
          and other data  needed for training. This path is passed to your TensorFlow
          program as the  `job-dir` command-line argument. The benefit of specifying
          this field is  that Cloud ML validates the path for use in training.", "name":
          "job_dir", "type": "GCSPath"}, {"default": "", "description": "The version
          of Python used in training. If not set, the default version is `2.7`. Python
          `3.5` is available when runtimeVersion is set to `1.4` and above.", "name":
          "python_version", "type": "String"}, {"default": "", "description": "The
          Cloud ML Engine runtime version to use for training. If not set, Cloud ML
          Engine uses the default stable version, 1.0.", "name": "runtime_version",
          "type": "String"}, {"default": "", "description": "The Docker image to run
          on the master replica. This image must be in Container Registry.", "name":
          "master_image_uri", "type": "GCRPath"}, {"default": "", "description": "The
          Docker image to run on the worker replica. This image must be in Container
          Registry.", "name": "worker_image_uri", "type": "GCRPath"}, {"default":
          "", "description": "The input parameters to create a training job. It is
          the JSON payload  of a [TrainingInput](https://cloud.google.com/ml-engine/reference/rest/v1/projects.jobs#TrainingInput)",
          "name": "training_input", "type": "Dict"}, {"default": "", "description":
          "The prefix of the generated job id.", "name": "job_id_prefix", "type":
          "String"}, {"default": "30", "description": "Optional. A time-interval to
          wait for between calls to get the job status.  Defaults to 30.''", "name":
          "wait_interval", "type": "Integer"}], "metadata": {"labels": {"add-pod-env":
          "true"}}, "name": "Submitting a Cloud ML training job as a pipeline step",
          "outputs": [{"description": "The ID of the created job.", "name": "job_id",
          "type": "String"}, {"description": "The output path in Cloud Storage of
          the trainning job, which contains  the trained model files.", "name": "job_dir",
          "type": "GCSPath"}, {"name": "MLPipeline UI metadata", "type": "UI metadata"}]}',
        pipelines.kubeflow.org/component_ref: '{"digest": "c05c450e73cf6fc6fd702d86fb6ae06734a7a69f6281d5175e842be39394e206",
          "name": "ml_engine/train", "url": "https://raw.githubusercontent.com/kubeflow/pipelines/0.2.5/components/gcp/ml_engine/train/component.yaml"}',
        pipelines.kubeflow.org/arguments.parameters: '{"args": "[\"--training_dataset_path\",
          \"{{inputs.parameters.bigquery-query-output_gcs_path}}\", \"--validation_dataset_path\",
          \"{{inputs.parameters.bigquery-query-2-output_gcs_path}}\", \"--hptune\",
          \"True\"]", "job_dir": "{{inputs.parameters.gcs_root}}/jobdir/hypertune/{{workflow.uid}}",
          "job_id_prefix": "", "master_image_uri": "gcr.io/zeta-rush-341516/trainer_image:latest",
          "package_uris": "", "project_id": "{{inputs.parameters.project_id}}", "python_module":
          "", "python_version": "", "region": "{{inputs.parameters.region}}", "runtime_version":
          "", "training_input": "{{inputs.parameters.hypertune_settings}}", "wait_interval":
          "30", "worker_image_uri": ""}'}
  - name: submitting-a-cloud-ml-training-job-as-a-pipeline-step-2
    container:
      args: [--ui_metadata_path, /tmp/outputs/MLPipeline_UI_metadata/data, kfp_component.google.ml_engine,
        train, --project_id, '{{inputs.parameters.project_id}}', --python_module,
        '', --package_uris, '', --region, '{{inputs.parameters.region}}', --args,
        '["--training_dataset_path", "{{inputs.parameters.bigquery-query-output_gcs_path}}",
          "--validation_dataset_path", "{{inputs.parameters.bigquery-query-2-output_gcs_path}}",
          "--alpha", "{{inputs.parameters.retrieve-best-run-alpha}}", "--max_iter",
          "{{inputs.parameters.retrieve-best-run-max_iter}}", "--hptune", "False"]',
        --job_dir, '{{inputs.parameters.gcs_root}}/jobdir/{{workflow.uid}}', --python_version,
        '', --runtime_version, '', --master_image_uri, 'gcr.io/zeta-rush-341516/trainer_image:latest',
        --worker_image_uri, '', --training_input, '', --job_id_prefix, '', --wait_interval,
        '30']
      command: []
      env:
      - {name: KFP_POD_NAME, value: '{{pod.name}}'}
      - name: KFP_POD_NAME
        valueFrom:
          fieldRef: {fieldPath: metadata.name}
      - name: KFP_POD_UID
        valueFrom:
          fieldRef: {fieldPath: metadata.uid}
      - name: KFP_NAMESPACE
        valueFrom:
          fieldRef: {fieldPath: metadata.namespace}
      - name: WORKFLOW_ID
        valueFrom:
          fieldRef: {fieldPath: 'metadata.labels[''workflows.argoproj.io/workflow'']'}
      - name: KFP_RUN_ID
        valueFrom:
          fieldRef: {fieldPath: 'metadata.labels[''pipeline/runid'']'}
      - name: ENABLE_CACHING
        valueFrom:
          fieldRef: {fieldPath: 'metadata.labels[''pipelines.kubeflow.org/enable_caching'']'}
      image: gcr.io/ml-pipeline/ml-pipeline-gcp:e66dcb18607406330f953bf99b04fe7c3ed1a4a8
    inputs:
      parameters:
      - {name: bigquery-query-2-output_gcs_path}
      - {name: bigquery-query-output_gcs_path}
      - {name: gcs_root}
      - {name: project_id}
      - {name: region}
      - {name: retrieve-best-run-alpha}
      - {name: retrieve-best-run-max_iter}
    outputs:
      parameters:
      - name: submitting-a-cloud-ml-training-job-as-a-pipeline-step-2-job_dir
        valueFrom: {path: /tmp/kfp/output/ml_engine/job_dir.txt}
      artifacts:
      - {name: mlpipeline-ui-metadata, path: /tmp/outputs/MLPipeline_UI_metadata/data}
      - {name: submitting-a-cloud-ml-training-job-as-a-pipeline-step-2-job_dir, path: /tmp/kfp/output/ml_engine/job_dir.txt}
      - {name: submitting-a-cloud-ml-training-job-as-a-pipeline-step-2-job_id, path: /tmp/kfp/output/ml_engine/job_id.txt}
    metadata:
      labels:
        add-pod-env: "true"
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.11
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/enable_caching: "true"
      annotations: {pipelines.kubeflow.org/component_spec: '{"description": "A Kubeflow
          Pipeline component to submit a Cloud Machine Learning (Cloud ML) \nEngine
          training job as a step in a pipeline.\n", "implementation": {"container":
          {"args": ["--ui_metadata_path", {"outputPath": "MLPipeline UI metadata"},
          "kfp_component.google.ml_engine", "train", "--project_id", {"inputValue":
          "project_id"}, "--python_module", {"inputValue": "python_module"}, "--package_uris",
          {"inputValue": "package_uris"}, "--region", {"inputValue": "region"}, "--args",
          {"inputValue": "args"}, "--job_dir", {"inputValue": "job_dir"}, "--python_version",
          {"inputValue": "python_version"}, "--runtime_version", {"inputValue": "runtime_version"},
          "--master_image_uri", {"inputValue": "master_image_uri"}, "--worker_image_uri",
          {"inputValue": "worker_image_uri"}, "--training_input", {"inputValue": "training_input"},
          "--job_id_prefix", {"inputValue": "job_id_prefix"}, "--wait_interval", {"inputValue":
          "wait_interval"}], "env": {"KFP_POD_NAME": "{{pod.name}}"}, "fileOutputs":
          {"job_dir": "/tmp/kfp/output/ml_engine/job_dir.txt", "job_id": "/tmp/kfp/output/ml_engine/job_id.txt"},
          "image": "gcr.io/ml-pipeline/ml-pipeline-gcp:e66dcb18607406330f953bf99b04fe7c3ed1a4a8"}},
          "inputs": [{"description": "Required. The ID of the parent project of the
          job.", "name": "project_id", "type": "GCPProjectID"}, {"default": "", "description":
          "The Python module name to run after installing the packages.", "name":
          "python_module", "type": "String"}, {"default": "", "description": "The
          Cloud Storage location of the packages (that contain the training program  and
          any additional dependencies). The maximum number of package URIs is 100.",
          "name": "package_uris", "type": "List"}, {"default": "", "description":
          "The Compute Engine region in which the training job is run.", "name": "region",
          "type": "GCPRegion"}, {"default": "", "description": "The command line arguments
          to pass to the program.", "name": "args", "type": "List"}, {"default": "",
          "description": "A Cloud Storage path in which to store the training outputs
          and other data  needed for training. This path is passed to your TensorFlow
          program as the  `job-dir` command-line argument. The benefit of specifying
          this field is  that Cloud ML validates the path for use in training.", "name":
          "job_dir", "type": "GCSPath"}, {"default": "", "description": "The version
          of Python used in training. If not set, the default version is `2.7`. Python
          `3.5` is available when runtimeVersion is set to `1.4` and above.", "name":
          "python_version", "type": "String"}, {"default": "", "description": "The
          Cloud ML Engine runtime version to use for training. If not set, Cloud ML
          Engine uses the default stable version, 1.0.", "name": "runtime_version",
          "type": "String"}, {"default": "", "description": "The Docker image to run
          on the master replica. This image must be in Container Registry.", "name":
          "master_image_uri", "type": "GCRPath"}, {"default": "", "description": "The
          Docker image to run on the worker replica. This image must be in Container
          Registry.", "name": "worker_image_uri", "type": "GCRPath"}, {"default":
          "", "description": "The input parameters to create a training job. It is
          the JSON payload  of a [TrainingInput](https://cloud.google.com/ml-engine/reference/rest/v1/projects.jobs#TrainingInput)",
          "name": "training_input", "type": "Dict"}, {"default": "", "description":
          "The prefix of the generated job id.", "name": "job_id_prefix", "type":
          "String"}, {"default": "30", "description": "Optional. A time-interval to
          wait for between calls to get the job status.  Defaults to 30.''", "name":
          "wait_interval", "type": "Integer"}], "metadata": {"labels": {"add-pod-env":
          "true"}}, "name": "Submitting a Cloud ML training job as a pipeline step",
          "outputs": [{"description": "The ID of the created job.", "name": "job_id",
          "type": "String"}, {"description": "The output path in Cloud Storage of
          the trainning job, which contains  the trained model files.", "name": "job_dir",
          "type": "GCSPath"}, {"name": "MLPipeline UI metadata", "type": "UI metadata"}]}',
        pipelines.kubeflow.org/component_ref: '{"digest": "c05c450e73cf6fc6fd702d86fb6ae06734a7a69f6281d5175e842be39394e206",
          "name": "ml_engine/train", "url": "https://raw.githubusercontent.com/kubeflow/pipelines/0.2.5/components/gcp/ml_engine/train/component.yaml"}',
        pipelines.kubeflow.org/arguments.parameters: '{"args": "[\"--training_dataset_path\",
          \"{{inputs.parameters.bigquery-query-output_gcs_path}}\", \"--validation_dataset_path\",
          \"{{inputs.parameters.bigquery-query-2-output_gcs_path}}\", \"--alpha\",
          \"{{inputs.parameters.retrieve-best-run-alpha}}\", \"--max_iter\", \"{{inputs.parameters.retrieve-best-run-max_iter}}\",
          \"--hptune\", \"False\"]", "job_dir": "{{inputs.parameters.gcs_root}}/jobdir/{{workflow.uid}}",
          "job_id_prefix": "", "master_image_uri": "gcr.io/zeta-rush-341516/trainer_image:latest",
          "package_uris": "", "project_id": "{{inputs.parameters.project_id}}", "python_module":
          "", "python_version": "", "region": "{{inputs.parameters.region}}", "runtime_version":
          "", "training_input": "", "wait_interval": "30", "worker_image_uri": ""}'}
  arguments:
    parameters:
    - {name: project_id}
    - {name: region}
    - {name: source_table_name}
    - {name: gcs_root}
    - {name: dataset_id}
    - {name: evaluation_metric_name}
    - {name: evaluation_metric_threshold}
    - {name: model_id}
    - {name: version_id}
    - {name: replace_existing_version}
    - name: hypertune_settings
      value: |2

        {
            "hyperparameters":  {
                "goal": "MAXIMIZE",
                "maxTrials": 6,
                "maxParallelTrials": 3,
                "hyperparameterMetricTag": "accuracy",
                "enableTrialEarlyStopping": True,
                "params": [
                    {
                        "parameterName": "max_iter",
                        "type": "DISCRETE",
                        "discreteValues": [500, 1000]
                    },
                    {
                        "parameterName": "alpha",
                        "type": "DOUBLE",
                        "minValue": 0.0001,
                        "maxValue": 0.001,
                        "scaleType": "UNIT_LINEAR_SCALE"
                    }
                ]
            }
        }
    - {name: dataset_location, value: US}
  serviceAccountName: pipeline-runner
